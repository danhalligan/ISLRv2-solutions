<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Moving Beyond Linearity | An Introduction to Statistical Learning</title>
  <meta name="description" content="7 Moving Beyond Linearity | An Introduction to Statistical Learning" />
  <meta name="generator" content="bookdown 0.29.3 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Moving Beyond Linearity | An Introduction to Statistical Learning" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Moving Beyond Linearity | An Introduction to Statistical Learning" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-model-selection-and-regularization.html"/>
<link rel="next" href="tree-based-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="islrv2.css" type="text/css" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/aaaakshat/cm-web-fonts@latest/fonts.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ISLRv2 Solutions</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistical-learning.html"><a href="statistical-learning.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#conceptual"><i class="fa fa-check"></i><b>2.1</b> Conceptual</a><ul>
<li class="chapter" data-level="2.1.1" data-path="statistical-learning.html"><a href="statistical-learning.html#question-1"><i class="fa fa-check"></i><b>2.1.1</b> Question 1</a></li>
<li class="chapter" data-level="2.1.2" data-path="statistical-learning.html"><a href="statistical-learning.html#question-2"><i class="fa fa-check"></i><b>2.1.2</b> Question 2</a></li>
<li class="chapter" data-level="2.1.3" data-path="statistical-learning.html"><a href="statistical-learning.html#question-3"><i class="fa fa-check"></i><b>2.1.3</b> Question 3</a></li>
<li class="chapter" data-level="2.1.4" data-path="statistical-learning.html"><a href="statistical-learning.html#question-4"><i class="fa fa-check"></i><b>2.1.4</b> Question 4</a></li>
<li class="chapter" data-level="2.1.5" data-path="statistical-learning.html"><a href="statistical-learning.html#question-5"><i class="fa fa-check"></i><b>2.1.5</b> Question 5</a></li>
<li class="chapter" data-level="2.1.6" data-path="statistical-learning.html"><a href="statistical-learning.html#question-6"><i class="fa fa-check"></i><b>2.1.6</b> Question 6</a></li>
<li class="chapter" data-level="2.1.7" data-path="statistical-learning.html"><a href="statistical-learning.html#question-7"><i class="fa fa-check"></i><b>2.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#applied"><i class="fa fa-check"></i><b>2.2</b> Applied</a><ul>
<li class="chapter" data-level="2.2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#question-8"><i class="fa fa-check"></i><b>2.2.1</b> Question 8</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#question-9"><i class="fa fa-check"></i><b>2.2.2</b> Question 9</a></li>
<li class="chapter" data-level="2.2.3" data-path="statistical-learning.html"><a href="statistical-learning.html#question-10"><i class="fa fa-check"></i><b>2.2.3</b> Question 10</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#conceptual-1"><i class="fa fa-check"></i><b>3.1</b> Conceptual</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#question-1-1"><i class="fa fa-check"></i><b>3.1.1</b> Question 1</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#question-2-1"><i class="fa fa-check"></i><b>3.1.2</b> Question 2</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#question-3-1"><i class="fa fa-check"></i><b>3.1.3</b> Question 3</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-regression.html"><a href="linear-regression.html#question-4-1"><i class="fa fa-check"></i><b>3.1.4</b> Question 4</a></li>
<li class="chapter" data-level="3.1.5" data-path="linear-regression.html"><a href="linear-regression.html#question-5-1"><i class="fa fa-check"></i><b>3.1.5</b> Question 5</a></li>
<li class="chapter" data-level="3.1.6" data-path="linear-regression.html"><a href="linear-regression.html#question-6-1"><i class="fa fa-check"></i><b>3.1.6</b> Question 6</a></li>
<li class="chapter" data-level="3.1.7" data-path="linear-regression.html"><a href="linear-regression.html#question-7-1"><i class="fa fa-check"></i><b>3.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#applied-1"><i class="fa fa-check"></i><b>3.2</b> Applied</a><ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#question-8-1"><i class="fa fa-check"></i><b>3.2.1</b> Question 8</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#question-9-1"><i class="fa fa-check"></i><b>3.2.2</b> Question 9</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regression.html"><a href="linear-regression.html#question-10-1"><i class="fa fa-check"></i><b>3.2.3</b> Question 10</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regression.html"><a href="linear-regression.html#question-11"><i class="fa fa-check"></i><b>3.2.4</b> Question 11</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regression.html"><a href="linear-regression.html#question-12"><i class="fa fa-check"></i><b>3.2.5</b> Question 12</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regression.html"><a href="linear-regression.html#question-13"><i class="fa fa-check"></i><b>3.2.6</b> Question 13</a></li>
<li class="chapter" data-level="3.2.7" data-path="linear-regression.html"><a href="linear-regression.html#question-14"><i class="fa fa-check"></i><b>3.2.7</b> Question 14</a></li>
<li class="chapter" data-level="3.2.8" data-path="linear-regression.html"><a href="linear-regression.html#question-15"><i class="fa fa-check"></i><b>3.2.8</b> Question 15</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification</a><ul>
<li class="chapter" data-level="4.1" data-path="classification.html"><a href="classification.html#conceptual-2"><i class="fa fa-check"></i><b>4.1</b> Conceptual</a><ul>
<li class="chapter" data-level="4.1.1" data-path="classification.html"><a href="classification.html#question-1-2"><i class="fa fa-check"></i><b>4.1.1</b> Question 1</a></li>
<li class="chapter" data-level="4.1.2" data-path="classification.html"><a href="classification.html#question-2-2"><i class="fa fa-check"></i><b>4.1.2</b> Question 2</a></li>
<li class="chapter" data-level="4.1.3" data-path="classification.html"><a href="classification.html#question-3-2"><i class="fa fa-check"></i><b>4.1.3</b> Question 3</a></li>
<li class="chapter" data-level="4.1.4" data-path="classification.html"><a href="classification.html#question-4-2"><i class="fa fa-check"></i><b>4.1.4</b> Question 4</a></li>
<li class="chapter" data-level="4.1.5" data-path="classification.html"><a href="classification.html#question-5-2"><i class="fa fa-check"></i><b>4.1.5</b> Question 5</a></li>
<li class="chapter" data-level="4.1.6" data-path="classification.html"><a href="classification.html#question-6-2"><i class="fa fa-check"></i><b>4.1.6</b> Question 6</a></li>
<li class="chapter" data-level="4.1.7" data-path="classification.html"><a href="classification.html#question-7-2"><i class="fa fa-check"></i><b>4.1.7</b> Question 7</a></li>
<li class="chapter" data-level="4.1.8" data-path="classification.html"><a href="classification.html#question-8-2"><i class="fa fa-check"></i><b>4.1.8</b> Question 8</a></li>
<li class="chapter" data-level="4.1.9" data-path="classification.html"><a href="classification.html#question-9-2"><i class="fa fa-check"></i><b>4.1.9</b> Question 9</a></li>
<li class="chapter" data-level="4.1.10" data-path="classification.html"><a href="classification.html#question-10-2"><i class="fa fa-check"></i><b>4.1.10</b> Question 10</a></li>
<li class="chapter" data-level="4.1.11" data-path="classification.html"><a href="classification.html#question-11-1"><i class="fa fa-check"></i><b>4.1.11</b> Question 11</a></li>
<li class="chapter" data-level="4.1.12" data-path="classification.html"><a href="classification.html#question-12-1"><i class="fa fa-check"></i><b>4.1.12</b> Question 12</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="classification.html"><a href="classification.html#applied-2"><i class="fa fa-check"></i><b>4.2</b> Applied</a><ul>
<li class="chapter" data-level="4.2.1" data-path="classification.html"><a href="classification.html#question-13-1"><i class="fa fa-check"></i><b>4.2.1</b> Question 13</a></li>
<li class="chapter" data-level="4.2.2" data-path="classification.html"><a href="classification.html#question-14-1"><i class="fa fa-check"></i><b>4.2.2</b> Question 14</a></li>
<li class="chapter" data-level="4.2.3" data-path="classification.html"><a href="classification.html#question-15-1"><i class="fa fa-check"></i><b>4.2.3</b> Question 15</a></li>
<li class="chapter" data-level="4.2.4" data-path="classification.html"><a href="classification.html#question-13-2"><i class="fa fa-check"></i><b>4.2.4</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="resampling-methods.html"><a href="resampling-methods.html#conceptual-3"><i class="fa fa-check"></i><b>5.1</b> Conceptual</a><ul>
<li class="chapter" data-level="5.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#question-1-3"><i class="fa fa-check"></i><b>5.1.1</b> Question 1</a></li>
<li class="chapter" data-level="5.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#question-2-3"><i class="fa fa-check"></i><b>5.1.2</b> Question 2</a></li>
<li class="chapter" data-level="5.1.3" data-path="resampling-methods.html"><a href="resampling-methods.html#question-3-3"><i class="fa fa-check"></i><b>5.1.3</b> Question 3</a></li>
<li class="chapter" data-level="5.1.4" data-path="resampling-methods.html"><a href="resampling-methods.html#question-4-3"><i class="fa fa-check"></i><b>5.1.4</b> Question 4</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="resampling-methods.html"><a href="resampling-methods.html#applied-3"><i class="fa fa-check"></i><b>5.2</b> Applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="resampling-methods.html"><a href="resampling-methods.html#question-5-3"><i class="fa fa-check"></i><b>5.2.1</b> Question 5</a></li>
<li class="chapter" data-level="5.2.2" data-path="resampling-methods.html"><a href="resampling-methods.html#question-6-3"><i class="fa fa-check"></i><b>5.2.2</b> Question 6</a></li>
<li class="chapter" data-level="5.2.3" data-path="resampling-methods.html"><a href="resampling-methods.html#question-7-3"><i class="fa fa-check"></i><b>5.2.3</b> Question 7</a></li>
<li class="chapter" data-level="5.2.4" data-path="resampling-methods.html"><a href="resampling-methods.html#question-8-3"><i class="fa fa-check"></i><b>5.2.4</b> Question 8</a></li>
<li class="chapter" data-level="5.2.5" data-path="resampling-methods.html"><a href="resampling-methods.html#question-9-3"><i class="fa fa-check"></i><b>5.2.5</b> Question 9</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html"><i class="fa fa-check"></i><b>6</b> Linear Model Selection and Regularization</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#conceptual-4"><i class="fa fa-check"></i><b>6.1</b> Conceptual</a><ul>
<li class="chapter" data-level="6.1.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-1-4"><i class="fa fa-check"></i><b>6.1.1</b> Question 1</a></li>
<li class="chapter" data-level="6.1.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-2-4"><i class="fa fa-check"></i><b>6.1.2</b> Question 2</a></li>
<li class="chapter" data-level="6.1.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-3-4"><i class="fa fa-check"></i><b>6.1.3</b> Question 3</a></li>
<li class="chapter" data-level="6.1.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-4-4"><i class="fa fa-check"></i><b>6.1.4</b> Question 4</a></li>
<li class="chapter" data-level="6.1.5" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-5-4"><i class="fa fa-check"></i><b>6.1.5</b> Question 5</a></li>
<li class="chapter" data-level="6.1.6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-6-4"><i class="fa fa-check"></i><b>6.1.6</b> Question 6</a></li>
<li class="chapter" data-level="6.1.7" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-7-4"><i class="fa fa-check"></i><b>6.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#applied-4"><i class="fa fa-check"></i><b>6.2</b> Applied</a><ul>
<li class="chapter" data-level="6.2.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-8-4"><i class="fa fa-check"></i><b>6.2.1</b> Question 8</a></li>
<li class="chapter" data-level="6.2.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-9-4"><i class="fa fa-check"></i><b>6.2.2</b> Question 9</a></li>
<li class="chapter" data-level="6.2.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-10-3"><i class="fa fa-check"></i><b>6.2.3</b> Question 10</a></li>
<li class="chapter" data-level="6.2.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-11-2"><i class="fa fa-check"></i><b>6.2.4</b> Question 11</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html"><i class="fa fa-check"></i><b>7</b> Moving Beyond Linearity</a><ul>
<li class="chapter" data-level="7.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#conceptual-5"><i class="fa fa-check"></i><b>7.1</b> Conceptual</a><ul>
<li class="chapter" data-level="7.1.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-1-5"><i class="fa fa-check"></i><b>7.1.1</b> Question 1</a></li>
<li class="chapter" data-level="7.1.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-2-5"><i class="fa fa-check"></i><b>7.1.2</b> Question 2</a></li>
<li class="chapter" data-level="7.1.3" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-3-5"><i class="fa fa-check"></i><b>7.1.3</b> Question 3</a></li>
<li class="chapter" data-level="7.1.4" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-4-5"><i class="fa fa-check"></i><b>7.1.4</b> Question 4</a></li>
<li class="chapter" data-level="7.1.5" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-5-5"><i class="fa fa-check"></i><b>7.1.5</b> Question 5</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#applied-5"><i class="fa fa-check"></i><b>7.2</b> Applied</a><ul>
<li class="chapter" data-level="7.2.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-6-5"><i class="fa fa-check"></i><b>7.2.1</b> Question 6</a></li>
<li class="chapter" data-level="7.2.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-7-5"><i class="fa fa-check"></i><b>7.2.2</b> Question 7</a></li>
<li class="chapter" data-level="7.2.3" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-8-5"><i class="fa fa-check"></i><b>7.2.3</b> Question 8</a></li>
<li class="chapter" data-level="7.2.4" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-9-5"><i class="fa fa-check"></i><b>7.2.4</b> Question 9</a></li>
<li class="chapter" data-level="7.2.5" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-10-4"><i class="fa fa-check"></i><b>7.2.5</b> Question 10</a></li>
<li class="chapter" data-level="7.2.6" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-11-3"><i class="fa fa-check"></i><b>7.2.6</b> Question 11</a></li>
<li class="chapter" data-level="7.2.7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-12-2"><i class="fa fa-check"></i><b>7.2.7</b> Question 12</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>8</b> Tree-Based Methods</a><ul>
<li class="chapter" data-level="8.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#conceptual-6"><i class="fa fa-check"></i><b>8.1</b> Conceptual</a><ul>
<li class="chapter" data-level="8.1.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-1-6"><i class="fa fa-check"></i><b>8.1.1</b> Question 1</a></li>
<li class="chapter" data-level="8.1.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-2-6"><i class="fa fa-check"></i><b>8.1.2</b> Question 2</a></li>
<li class="chapter" data-level="8.1.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-3-6"><i class="fa fa-check"></i><b>8.1.3</b> Question 3</a></li>
<li class="chapter" data-level="8.1.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-4-6"><i class="fa fa-check"></i><b>8.1.4</b> Question 4</a></li>
<li class="chapter" data-level="8.1.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-5-6"><i class="fa fa-check"></i><b>8.1.5</b> Question 5</a></li>
<li class="chapter" data-level="8.1.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-6-6"><i class="fa fa-check"></i><b>8.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#applied-6"><i class="fa fa-check"></i><b>8.2</b> Applied</a><ul>
<li class="chapter" data-level="8.2.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-7-6"><i class="fa fa-check"></i><b>8.2.1</b> Question 7</a></li>
<li class="chapter" data-level="8.2.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-8-6"><i class="fa fa-check"></i><b>8.2.2</b> Question 8</a></li>
<li class="chapter" data-level="8.2.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-9-6"><i class="fa fa-check"></i><b>8.2.3</b> Question 9</a></li>
<li class="chapter" data-level="8.2.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-10-5"><i class="fa fa-check"></i><b>8.2.4</b> Question 10</a></li>
<li class="chapter" data-level="8.2.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-11-4"><i class="fa fa-check"></i><b>8.2.5</b> Question 11</a></li>
<li class="chapter" data-level="8.2.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-12-3"><i class="fa fa-check"></i><b>8.2.6</b> Question 12</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>9</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="9.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#conceptual-7"><i class="fa fa-check"></i><b>9.1</b> Conceptual</a><ul>
<li class="chapter" data-level="9.1.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-1-7"><i class="fa fa-check"></i><b>9.1.1</b> Question 1</a></li>
<li class="chapter" data-level="9.1.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-2-7"><i class="fa fa-check"></i><b>9.1.2</b> Question 2</a></li>
<li class="chapter" data-level="9.1.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-3-7"><i class="fa fa-check"></i><b>9.1.3</b> Question 3</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#applied-7"><i class="fa fa-check"></i><b>9.2</b> Applied</a><ul>
<li class="chapter" data-level="9.2.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-4-7"><i class="fa fa-check"></i><b>9.2.1</b> Question 4</a></li>
<li class="chapter" data-level="9.2.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-5-7"><i class="fa fa-check"></i><b>9.2.2</b> Question 5</a></li>
<li class="chapter" data-level="9.2.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-6-7"><i class="fa fa-check"></i><b>9.2.3</b> Question 6</a></li>
<li class="chapter" data-level="9.2.4" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-7-7"><i class="fa fa-check"></i><b>9.2.4</b> Question 7</a></li>
<li class="chapter" data-level="9.2.5" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-8-7"><i class="fa fa-check"></i><b>9.2.5</b> Question 8</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>10</b> Deep Learning</a><ul>
<li class="chapter" data-level="10.1" data-path="deep-learning.html"><a href="deep-learning.html#conceptual-8"><i class="fa fa-check"></i><b>10.1</b> Conceptual</a><ul>
<li class="chapter" data-level="10.1.1" data-path="deep-learning.html"><a href="deep-learning.html#question-1-8"><i class="fa fa-check"></i><b>10.1.1</b> Question 1</a></li>
<li class="chapter" data-level="10.1.2" data-path="deep-learning.html"><a href="deep-learning.html#question-2-8"><i class="fa fa-check"></i><b>10.1.2</b> Question 2</a></li>
<li class="chapter" data-level="10.1.3" data-path="deep-learning.html"><a href="deep-learning.html#question-3-8"><i class="fa fa-check"></i><b>10.1.3</b> Question 3</a></li>
<li class="chapter" data-level="10.1.4" data-path="deep-learning.html"><a href="deep-learning.html#question-4-8"><i class="fa fa-check"></i><b>10.1.4</b> Question 4</a></li>
<li class="chapter" data-level="10.1.5" data-path="deep-learning.html"><a href="deep-learning.html#question-5-8"><i class="fa fa-check"></i><b>10.1.5</b> Question 5</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="deep-learning.html"><a href="deep-learning.html#applied-8"><i class="fa fa-check"></i><b>10.2</b> Applied</a><ul>
<li class="chapter" data-level="10.2.1" data-path="deep-learning.html"><a href="deep-learning.html#question-6-8"><i class="fa fa-check"></i><b>10.2.1</b> Question 6</a></li>
<li class="chapter" data-level="10.2.2" data-path="deep-learning.html"><a href="deep-learning.html#question-7-8"><i class="fa fa-check"></i><b>10.2.2</b> Question 7</a></li>
<li class="chapter" data-level="10.2.3" data-path="deep-learning.html"><a href="deep-learning.html#question-8-8"><i class="fa fa-check"></i><b>10.2.3</b> Question 8</a></li>
<li class="chapter" data-level="10.2.4" data-path="deep-learning.html"><a href="deep-learning.html#question-9-7"><i class="fa fa-check"></i><b>10.2.4</b> Question 9</a></li>
<li class="chapter" data-level="10.2.5" data-path="deep-learning.html"><a href="deep-learning.html#question-10-6"><i class="fa fa-check"></i><b>10.2.5</b> Question 10</a></li>
<li class="chapter" data-level="10.2.6" data-path="deep-learning.html"><a href="deep-learning.html#question-11-5"><i class="fa fa-check"></i><b>10.2.6</b> Question 11</a></li>
<li class="chapter" data-level="10.2.7" data-path="deep-learning.html"><a href="deep-learning.html#question-12-4"><i class="fa fa-check"></i><b>10.2.7</b> Question 12</a></li>
<li class="chapter" data-level="10.2.8" data-path="deep-learning.html"><a href="deep-learning.html#question-13-3"><i class="fa fa-check"></i><b>10.2.8</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html"><i class="fa fa-check"></i><b>11</b> Survival Analysis and Censored Data</a><ul>
<li class="chapter" data-level="11.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#conceptual-9"><i class="fa fa-check"></i><b>11.1</b> Conceptual</a><ul>
<li class="chapter" data-level="11.1.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-1-9"><i class="fa fa-check"></i><b>11.1.1</b> Question 1</a></li>
<li class="chapter" data-level="11.1.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-2-9"><i class="fa fa-check"></i><b>11.1.2</b> Question 2</a></li>
<li class="chapter" data-level="11.1.3" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-3-9"><i class="fa fa-check"></i><b>11.1.3</b> Question 3</a></li>
<li class="chapter" data-level="11.1.4" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-4-9"><i class="fa fa-check"></i><b>11.1.4</b> Question 4</a></li>
<li class="chapter" data-level="11.1.5" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-5-9"><i class="fa fa-check"></i><b>11.1.5</b> Question 5</a></li>
<li class="chapter" data-level="11.1.6" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-6-9"><i class="fa fa-check"></i><b>11.1.6</b> Question 6</a></li>
<li class="chapter" data-level="11.1.7" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-7-9"><i class="fa fa-check"></i><b>11.1.7</b> Question 7</a></li>
<li class="chapter" data-level="11.1.8" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-8-9"><i class="fa fa-check"></i><b>11.1.8</b> Question 8</a></li>
<li class="chapter" data-level="11.1.9" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-9-8"><i class="fa fa-check"></i><b>11.1.9</b> Question 9</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#applied-9"><i class="fa fa-check"></i><b>11.2</b> Applied</a><ul>
<li class="chapter" data-level="11.2.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-10-7"><i class="fa fa-check"></i><b>11.2.1</b> Question 10</a></li>
<li class="chapter" data-level="11.2.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-11-6"><i class="fa fa-check"></i><b>11.2.2</b> Question 11</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>12</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="12.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#conceptual-10"><i class="fa fa-check"></i><b>12.1</b> Conceptual</a><ul>
<li class="chapter" data-level="12.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-1-10"><i class="fa fa-check"></i><b>12.1.1</b> Question 1</a></li>
<li class="chapter" data-level="12.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-2-10"><i class="fa fa-check"></i><b>12.1.2</b> Question 2</a></li>
<li class="chapter" data-level="12.1.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-3-10"><i class="fa fa-check"></i><b>12.1.3</b> Question 3</a></li>
<li class="chapter" data-level="12.1.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-4-10"><i class="fa fa-check"></i><b>12.1.4</b> Question 4</a></li>
<li class="chapter" data-level="12.1.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-5-10"><i class="fa fa-check"></i><b>12.1.5</b> Question 5</a></li>
<li class="chapter" data-level="12.1.6" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-6-10"><i class="fa fa-check"></i><b>12.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#applied-10"><i class="fa fa-check"></i><b>12.2</b> Applied</a><ul>
<li class="chapter" data-level="12.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-7-10"><i class="fa fa-check"></i><b>12.2.1</b> Question 7</a></li>
<li class="chapter" data-level="12.2.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-8-10"><i class="fa fa-check"></i><b>12.2.2</b> Question 8</a></li>
<li class="chapter" data-level="12.2.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-9-9"><i class="fa fa-check"></i><b>12.2.3</b> Question 9</a></li>
<li class="chapter" data-level="12.2.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-10-8"><i class="fa fa-check"></i><b>12.2.4</b> Question 10</a></li>
<li class="chapter" data-level="12.2.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-11-7"><i class="fa fa-check"></i><b>12.2.5</b> Question 11</a></li>
<li class="chapter" data-level="12.2.6" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-12-5"><i class="fa fa-check"></i><b>12.2.6</b> Question 12</a></li>
<li class="chapter" data-level="12.2.7" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-13-4"><i class="fa fa-check"></i><b>12.2.7</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>13</b> Multiple Testing</a><ul>
<li class="chapter" data-level="13.1" data-path="multiple-testing.html"><a href="multiple-testing.html#conceptual-11"><i class="fa fa-check"></i><b>13.1</b> Conceptual</a><ul>
<li class="chapter" data-level="13.1.1" data-path="multiple-testing.html"><a href="multiple-testing.html#question-1-11"><i class="fa fa-check"></i><b>13.1.1</b> Question 1</a></li>
<li class="chapter" data-level="13.1.2" data-path="multiple-testing.html"><a href="multiple-testing.html#question-2-11"><i class="fa fa-check"></i><b>13.1.2</b> Question 2</a></li>
<li class="chapter" data-level="13.1.3" data-path="multiple-testing.html"><a href="multiple-testing.html#question-3-11"><i class="fa fa-check"></i><b>13.1.3</b> Question 3</a></li>
<li class="chapter" data-level="13.1.4" data-path="multiple-testing.html"><a href="multiple-testing.html#question-4-11"><i class="fa fa-check"></i><b>13.1.4</b> Question 4</a></li>
<li class="chapter" data-level="13.1.5" data-path="multiple-testing.html"><a href="multiple-testing.html#question-5-11"><i class="fa fa-check"></i><b>13.1.5</b> Question 5</a></li>
<li class="chapter" data-level="13.1.6" data-path="multiple-testing.html"><a href="multiple-testing.html#question-6-11"><i class="fa fa-check"></i><b>13.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="multiple-testing.html"><a href="multiple-testing.html#applied-11"><i class="fa fa-check"></i><b>13.2</b> Applied</a><ul>
<li class="chapter" data-level="13.2.1" data-path="multiple-testing.html"><a href="multiple-testing.html#question-7-11"><i class="fa fa-check"></i><b>13.2.1</b> Question 7</a></li>
<li class="chapter" data-level="13.2.2" data-path="multiple-testing.html"><a href="multiple-testing.html#question-8-11"><i class="fa fa-check"></i><b>13.2.2</b> Question 8</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="moving-beyond-linearity" class="section level1 hasAnchor">
<h1><span class="header-section-number">7</span> Moving Beyond Linearity<a href="moving-beyond-linearity.html#moving-beyond-linearity" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="conceptual-5" class="section level2 hasAnchor">
<h2><span class="header-section-number">7.1</span> Conceptual<a href="moving-beyond-linearity.html#conceptual-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="question-1-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.1</span> Question 1<a href="moving-beyond-linearity.html#question-1-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>It was mentioned in the chapter that a cubic regression spline with one knot
at <span class="math inline">\(\xi\)</span> can be obtained using a basis of the form <span class="math inline">\(x, x^2, x^3, (x-\xi)^3_+\)</span>,
where <span class="math inline">\((x-\xi)^3_+ = (x-\xi)^3\)</span> if <span class="math inline">\(x&gt;\xi\)</span> and equals 0 otherwise. We will now
show that a function of the form
<span class="math display">\[
f(x)=\beta_0 +\beta_1x+\beta_2x^2 +\beta_3x^3 +\beta_4(x-\xi)^3_+
\]</span>
is indeed a cubic regression spline, regardless of the values of
<span class="math inline">\(\beta_0, \beta_1, \beta_2, \beta_3,\beta_4\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Find a cubic polynomial
<span class="math display">\[
f_1(x) = a_1 + b_1x + c_1x^2 + d_1x^3
\]</span>
such that <span class="math inline">\(f(x) = f_1(x)\)</span> for all <span class="math inline">\(x \le \xi\)</span>. Express <span class="math inline">\(a_1,b_1,c_1,d_1\)</span> in
terms of <span class="math inline">\(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4\)</span>.</li>
</ol>
</blockquote>
<p>In this case, for <span class="math inline">\(x \le \xi\)</span>, the cubic polynomial simply has terms
<span class="math inline">\(a_1 = \beta_0\)</span>, <span class="math inline">\(b_1 = \beta_1\)</span>, <span class="math inline">\(c_1 = \beta_2\)</span>, <span class="math inline">\(d_1 = \beta_3\)</span></p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Find a cubic polynomial
<span class="math display">\[
f_2(x) = a_2 + b_2x + c_2x^2 + d_2x^3
\]</span>
such that <span class="math inline">\(f(x) = f_2(x)\)</span> for all <span class="math inline">\(x &gt; \xi\)</span>. Express <span class="math inline">\(a_2, b_2, c_2, d_2\)</span> in
terms of <span class="math inline">\(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4\)</span>. We have now established
that <span class="math inline">\(f(x)\)</span> is a piecewise polynomial.</li>
</ol>
</blockquote>
<p>For <span class="math inline">\(x \gt \xi\)</span>, the cubic polynomial would be (we include the <span class="math inline">\(\beta_4\)</span> term).
<span class="math display">\[\begin{align}
f(x) = &amp; \beta_0 + \beta_1x + \beta_2x^2 + \beta_3x^3 + \beta_4(x-\xi)^3 \\
     = &amp; \beta_0 + \beta_1x + \beta_2x^2 +  + \beta_4(x^3 - 3x^2\xi + 3x\xi^2 -\xi^3) \\
     = &amp; \beta_0 - \beta_4\xi^3 + (\beta_1 + 3\beta_4\xi^2)x +
         (\beta_2 - 3\beta_4\xi)x^2 + (\beta_3 + \beta_4)x^3
\end{align}\]</span></p>
<p>Therefore,
<span class="math inline">\(a_1 = \beta_0 - \beta_4\xi^3\)</span>, <span class="math inline">\(b_1 = \beta_1 + 3\beta_4\xi^2\)</span>,
<span class="math inline">\(c_1 = \beta_2 - 3\beta_4\xi\)</span>, <span class="math inline">\(d_1 = \beta_3 + \beta_4\)</span></p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Show that <span class="math inline">\(f_1(\xi) = f_2(\xi)\)</span>. That is, <span class="math inline">\(f(x)\)</span> is continuous at <span class="math inline">\(\xi\)</span>.</li>
</ol>
</blockquote>
<p>To do this, we replace <span class="math inline">\(x\)</span> with <span class="math inline">\(\xi\)</span> in the above equations and simplify.</p>
<p><span class="math display">\[\begin{align}
f_1(\xi) = \beta_0 + \beta_1\xi + \beta_2\xi^2 + \beta_3\xi^3
\end{align}\]</span></p>
<p><span class="math display">\[\begin{align}
f_2(\xi) = &amp; \beta_0 - \beta_4\xi^3 + (\beta_1 + 3\beta_4\xi^2)\xi +
             (\beta_2 - 3\beta_4\xi)\xi^2 + (\beta_3 + \beta_4)\xi^3 \\
         = &amp; \beta_0 - \beta_4\xi^3 + \beta_1\xi + 3\beta_4\xi^3 +
             \beta_2\xi^2 - 3\beta_4\xi^3 + \beta_3\xi^3 + \beta_4\xi^3 \\
         = &amp; \beta_0 + \beta_1\xi + \beta_2\xi^2 + \beta_3\xi^3
\end{align}\]</span></p>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>Show that <span class="math inline">\(f_1&#39;(\xi) = f_2&#39;(\xi)\)</span>. That is, <span class="math inline">\(f&#39;(x)\)</span> is continuous at <span class="math inline">\(\xi\)</span>.</li>
</ol>
</blockquote>
<p>To do this we differentiate the above with respect to <span class="math inline">\(x\)</span>.</p>
<p><span class="math display">\[
f_1&#39;(x) = \beta_1 + 2\beta_2x + 3\beta_3x^2
f_1&#39;(\xi) = \beta_1 + 2\beta_2\xi + 3\beta_3\xi^2
\]</span></p>
<p><span class="math display">\[\begin{align}
f_2&#39;(x)   &amp; = \beta_1 + 3\beta_4\xi^2 + 2(\beta_2 - 3\beta_4\xi)x + 3(\beta_3 + \beta_4)x^2 \\
f_2&#39;(\xi) &amp; = \beta_1 + 3\beta_4\xi^2 + 2(\beta_2 - 3\beta_4\xi)\xi + 3(\beta_3 + \beta_4)\xi^2 \\
          &amp; = \beta_1 + 3\beta_4\xi^2 + 2\beta_2\xi - 6\beta_4\xi^2 + 3\beta_3\xi^2 + 3\beta_4\xi^2 \\
          &amp; = \beta_1 + 2\beta_2\xi + 3\beta_3\xi^2
\end{align}\]</span></p>
<blockquote>
<ol start="5" style="list-style-type: lower-alpha">
<li>Show that <span class="math inline">\(f_1&#39;&#39;(\xi) = f_2&#39;&#39;(\xi)\)</span>. That is, <span class="math inline">\(f&#39;&#39;(x)\)</span> is continuous at <span class="math inline">\(\xi\)</span>.</li>
</ol>
<p>Therefore, <span class="math inline">\(f(x)\)</span> is indeed a cubic spline.</p>
</blockquote>
<p><span class="math display">\[
f_1&#39;(x) = 2\beta_2x + 6\beta_3x \\
f_1&#39;&#39;(\xi) = 2\beta_2\xi + 6\beta_3\xi
\]</span></p>
<p><span class="math display">\[
f_2&#39;&#39;(x) = 2\beta_2 - 6\beta_4\xi + 6(\beta_3 + \beta_4)x \\
\]</span>
<span class="math display">\[\begin{align}
f_2&#39;&#39;(\xi) &amp; = 2\beta_2 - 6\beta_4\xi + 6\beta_3\xi + 6\beta_4\xi \\
           &amp; = 2\beta_2 + 6\beta_3\xi
\end{align}\]</span></p>
<blockquote>
<p><em>Hint: Parts (d) and (e) of this problem require knowledge of single-variable
calculus. As a reminder, given a cubic polynomial</em>
<span class="math display">\[f_1(x) = a_1 + b_1x + c_1x^2 + d_1x^3,\]</span>
<em>the first derivative takes the form</em>
<span class="math display">\[f_1&#39;(x) = b_1 + 2c_1x + 3d_1x^2\]</span>
<em>and the second derivative takes the form</em>
<span class="math display">\[f_1&#39;&#39;(x) = 2c_1 + 6d_1x.\]</span></p>
</blockquote>
</div>
<div id="question-2-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.2</span> Question 2<a href="moving-beyond-linearity.html#question-2-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Suppose that a curve <span class="math inline">\(\hat{g}\)</span> is computed to smoothly fit a set of <span class="math inline">\(n\)</span> points
using the following formula:
<span class="math display">\[
\DeclareMathOperator*{\argmin}{arg\,min} % Jan Hlavacek
\hat{g} = \argmin_g \left(\sum_{i=1}^n (y_i - g(x_i))^2 + \lambda \int \left[ g^{(m)}(x) \right]^2 dx \right),
\]</span>
where <span class="math inline">\(g^{(m)}\)</span> represents the <span class="math inline">\(m\)</span>th derivative of <span class="math inline">\(g\)</span> (and <span class="math inline">\(g^{(0)} = g\)</span>).
Provide example sketches of <span class="math inline">\(\hat{g}\)</span> in each of the following scenarios.</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\lambda=\infty, m=0\)</span>.</li>
</ol>
</blockquote>
<p>Here we penalize the <span class="math inline">\(g\)</span> and a infinite <span class="math inline">\(\lambda\)</span> means that this penalty
dominates. This means that the <span class="math inline">\(\hat{g}\)</span> will be 0.</p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li><span class="math inline">\(\lambda=\infty, m=1\)</span>.</li>
</ol>
</blockquote>
<p>Here we penalize the first derivative (the slope) of <span class="math inline">\(g\)</span> and a infinite
<span class="math inline">\(\lambda\)</span> means that this penalty dominates. Thus the slope will be 0
(and otherwise best fitting <span class="math inline">\(x\)</span>, i.e. at the mean of <span class="math inline">\(x\)</span>).</p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li><span class="math inline">\(\lambda=\infty, m=2\)</span>.</li>
</ol>
</blockquote>
<p>Here we penalize the second derivative (the change of slope) of <span class="math inline">\(g\)</span> and a
infinite <span class="math inline">\(\lambda\)</span> means that this penalty dominates. Thus the line will be
straight (and otherwise best fitting <span class="math inline">\(x\)</span>).</p>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li><span class="math inline">\(\lambda=\infty, m=3\)</span>.</li>
</ol>
</blockquote>
<p>Here we penalize the third derivative (the change of the change of slope) of <span class="math inline">\(g\)</span>
and a infinite <span class="math inline">\(\lambda\)</span> means that this penalty dominates. In other words,
the curve will have a consistent rate of change (e.g. a quadratic
function or similar).</p>
<blockquote>
<ol start="5" style="list-style-type: lower-alpha">
<li><span class="math inline">\(\lambda=0, m=3\)</span>.</li>
</ol>
</blockquote>
<p>Here we penalize the third derivative, but a value of <span class="math inline">\(\lambda = 0\)</span> means that
there is no penalty. As a result, the curve is able to interpolate all points.</p>
</div>
<div id="question-3-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.3</span> Question 3<a href="moving-beyond-linearity.html#question-3-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Suppose we fit a curve with basis functions
<span class="math inline">\(b_1(X) = X\)</span>,
<span class="math inline">\(b_2(X) = (X - 1)^2I(X \geq 1)\)</span>.
(Note that <span class="math inline">\(I(X \geq 1)\)</span> equals 1 for <span class="math inline">\(X \geq 1\)</span> and 0 otherwise.) We fit the
linear regression model
<span class="math display">\[Y = \beta_0 +\beta_1b_1(X) + \beta_2b_2(X) + \epsilon,\]</span>
and obtain coefficient estimates
<span class="math inline">\(\hat{\beta}_0 = 1, \hat{\beta}_1 = 1, \hat{\beta}_2 = -2\)</span>.
Sketch the estimated curve between <span class="math inline">\(X = -2\)</span> and <span class="math inline">\(X = 2\)</span>. Note the intercepts,
slopes, and other relevant information.</p>
</blockquote>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="moving-beyond-linearity.html#cb410-1"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb410-2"><a href="moving-beyond-linearity.html#cb410-2"></a>f &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="dv">1</span> <span class="op">+</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span><span class="dv">-2</span> <span class="op">*</span><span class="st"> </span>(x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">I</span>(x <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb410-3"><a href="moving-beyond-linearity.html#cb410-3"></a><span class="kw">plot</span>(x, <span class="kw">f</span>(x), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb410-4"><a href="moving-beyond-linearity.html#cb410-4"></a><span class="kw">grid</span>()</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
</div>
<div id="question-4-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.4</span> Question 4<a href="moving-beyond-linearity.html#question-4-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Suppose we fit a curve with basis functions
<span class="math inline">\(b_1(X) = I(0 \leq X \leq 2) - (X -1)I(1 \leq X \leq 2),\)</span>
<span class="math inline">\(b_2(X) = (X -3)I(3 \leq X \leq 4) + I(4 \lt X \leq 5)\)</span>.
We fit the linear regression model
<span class="math display">\[Y = \beta_0 +\beta_1b_1(X) + \beta_2b_2(X) + \epsilon,\]</span>
and obtain coefficient estimates
<span class="math inline">\(\hat{\beta}_0 = 1, \hat{\beta}_1 = 1, \hat{\beta}_2 = 3\)</span>.
Sketch the estimated curve between <span class="math inline">\(X = -2\)</span> and <span class="math inline">\(X = 6\)</span>. Note the intercepts,
slopes, and other relevant information.</p>
</blockquote>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="moving-beyond-linearity.html#cb411-1"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">6</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb411-2"><a href="moving-beyond-linearity.html#cb411-2"></a>b1 &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">I</span>(<span class="dv">0</span> <span class="op">&lt;=</span><span class="st"> </span>x <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">2</span>) <span class="op">-</span><span class="st"> </span>(x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">1</span> <span class="op">&lt;=</span><span class="st"> </span>x <span class="op">&amp;</span><span class="st">  </span>x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">2</span>)</span>
<span id="cb411-3"><a href="moving-beyond-linearity.html#cb411-3"></a>b2 &lt;-<span class="st"> </span><span class="cf">function</span>(x) (x <span class="op">-</span><span class="st"> </span><span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">3</span> <span class="op">&lt;=</span><span class="st"> </span>x  <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(<span class="dv">4</span> <span class="op">&lt;</span><span class="st"> </span>x <span class="op">&amp;</span><span class="st"> </span>x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">5</span>)</span>
<span id="cb411-4"><a href="moving-beyond-linearity.html#cb411-4"></a>f &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">*</span><span class="kw">b1</span>(x) <span class="op">+</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span><span class="kw">b2</span>(x)</span>
<span id="cb411-5"><a href="moving-beyond-linearity.html#cb411-5"></a><span class="kw">plot</span>(x, <span class="kw">f</span>(x), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb411-6"><a href="moving-beyond-linearity.html#cb411-6"></a><span class="kw">grid</span>()</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="question-5-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.1.5</span> Question 5<a href="moving-beyond-linearity.html#question-5-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Consider two curves, <span class="math inline">\(\hat{g}\)</span> and <span class="math inline">\(\hat{g}_2\)</span>, defined by</p>
<p><span class="math display">\[
\hat{g}_1 = \argmin_g \left(\sum_{i=1}^n (y_i - g(x_i))^2 +
  \lambda \int \left[ g^{(3)}(x) \right]^2 dx \right),
\]</span>
<span class="math display">\[
\hat{g}_2 = \argmin_g \left(\sum_{i=1}^n (y_i - g(x_i))^2 +
  \lambda \int \left[ g^{(4)}(x) \right]^2 dx \right),
\]</span></p>
<p>where <span class="math inline">\(g^{(m)}\)</span> represents the <span class="math inline">\(m\)</span>th derivative of <span class="math inline">\(g\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>As <span class="math inline">\(\lambda \to \infty\)</span>, will <span class="math inline">\(\hat{g}_1\)</span> or <span class="math inline">\(\hat{g}_2\)</span> have the smaller
training RSS?</li>
</ol>
</blockquote>
<p><span class="math inline">\(\hat{g}_2\)</span> is more flexible (by penalizing a higher derivative of <span class="math inline">\(g\)</span>) and
so will have a smaller training RSS.</p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>As <span class="math inline">\(\lambda \to \infty\)</span>, will <span class="math inline">\(\hat{g}_1\)</span> or <span class="math inline">\(\hat{g}_2\)</span> have the smaller
test RSS?</li>
</ol>
</blockquote>
<p>We cannot tell which function will produce a smaller test RSS, but there is
chance that <span class="math inline">\(\hat{g}_1\)</span> will if <span class="math inline">\(\hat{g}_2\)</span> overfits the data.</p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>For <span class="math inline">\(\lambda = 0\)</span>, will <span class="math inline">\(\hat{g}_1\)</span> or <span class="math inline">\(\hat{g}_2\)</span> have the smaller training
and test RSS?</li>
</ol>
</blockquote>
<p>When <span class="math inline">\(\lambda = 0\)</span> there is no penalty, so both functions will give the same
result: perfect interpolation of the training data. Thus training RSS will be
0 but test RSS could be high.</p>
</div>
</div>
<div id="applied-5" class="section level2 hasAnchor">
<h2><span class="header-section-number">7.2</span> Applied<a href="moving-beyond-linearity.html#applied-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="question-6-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.1</span> Question 6<a href="moving-beyond-linearity.html#question-6-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>In this exercise, you will further analyze the <code>Wage</code> data set considered
throughout this chapter.</p>
<ol style="list-style-type: lower-alpha">
<li>Perform polynomial regression to predict <code>wage</code> using <code>age</code>. Use
cross-validation to select the optimal degree <span class="math inline">\(d\)</span> for the polynomial. What
degree was chosen, and how does this compare to the results of hypothesis
testing using ANOVA? Make a plot of the resulting polynomial fit to the data.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="moving-beyond-linearity.html#cb412-1"></a><span class="kw">library</span>(ISLR2)</span>
<span id="cb412-2"><a href="moving-beyond-linearity.html#cb412-2"></a><span class="kw">library</span>(boot)</span>
<span id="cb412-3"><a href="moving-beyond-linearity.html#cb412-3"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb412-4"><a href="moving-beyond-linearity.html#cb412-4"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb412-5"><a href="moving-beyond-linearity.html#cb412-5"></a>res &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="cf">function</span>(i) {</span>
<span id="cb412-6"><a href="moving-beyond-linearity.html#cb412-6"></a>  fit &lt;-<span class="st"> </span><span class="kw">glm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, i), <span class="dt">data =</span> Wage)</span>
<span id="cb412-7"><a href="moving-beyond-linearity.html#cb412-7"></a>  <span class="kw">cv.glm</span>(Wage, fit, <span class="dt">K =</span> <span class="dv">5</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb412-8"><a href="moving-beyond-linearity.html#cb412-8"></a>})</span>
<span id="cb412-9"><a href="moving-beyond-linearity.html#cb412-9"></a><span class="kw">which.min</span>(res)</span></code></pre></div>
<pre><code>## [1] 6</code></pre>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="moving-beyond-linearity.html#cb414-1"></a><span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, res, <span class="dt">xlab =</span> <span class="st">&quot;Degree&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Test MSE&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb414-2"><a href="moving-beyond-linearity.html#cb414-2"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">which.min</span>(res), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="moving-beyond-linearity.html#cb415-1"></a>fit &lt;-<span class="st"> </span><span class="kw">glm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="kw">which.min</span>(res)), <span class="dt">data =</span> Wage)</span>
<span id="cb415-2"><a href="moving-beyond-linearity.html#cb415-2"></a><span class="kw">plot</span>(Wage<span class="op">$</span>age, Wage<span class="op">$</span>wage, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">0.4</span>, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>))</span>
<span id="cb415-3"><a href="moving-beyond-linearity.html#cb415-3"></a><span class="kw">points</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">age =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>)), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-3-2.png" width="672" /></p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="moving-beyond-linearity.html#cb416-1"></a><span class="kw">summary</span>(<span class="kw">glm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">6</span>), <span class="dt">data =</span> Wage))</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = wage ~ poly(age, 6), data = Wage)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -98.521  -24.536   -4.848   15.471  202.108  
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    111.7036     0.7286 153.316  &lt; 2e-16 ***
## poly(age, 6)1  447.0679    39.9063  11.203  &lt; 2e-16 ***
## poly(age, 6)2 -478.3158    39.9063 -11.986  &lt; 2e-16 ***
## poly(age, 6)3  125.5217    39.9063   3.145  0.00167 ** 
## poly(age, 6)4  -77.9112    39.9063  -1.952  0.05099 .  
## poly(age, 6)5  -35.8129    39.9063  -0.897  0.36956    
## poly(age, 6)6   62.7077    39.9063   1.571  0.11620    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 1592.512)
## 
##     Null deviance: 5222086  on 2999  degrees of freedom
## Residual deviance: 4766389  on 2993  degrees of freedom
## AIC: 30642
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="moving-beyond-linearity.html#cb418-1"></a>fit1 &lt;-<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">1</span>), <span class="dt">data =</span> Wage)</span>
<span id="cb418-2"><a href="moving-beyond-linearity.html#cb418-2"></a>fit2 &lt;-<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">2</span>), <span class="dt">data =</span> Wage)</span>
<span id="cb418-3"><a href="moving-beyond-linearity.html#cb418-3"></a>fit3 &lt;-<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">3</span>), <span class="dt">data =</span> Wage)</span>
<span id="cb418-4"><a href="moving-beyond-linearity.html#cb418-4"></a>fit4 &lt;-<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">4</span>), <span class="dt">data =</span> Wage)</span>
<span id="cb418-5"><a href="moving-beyond-linearity.html#cb418-5"></a>fit5 &lt;-<span class="st"> </span><span class="kw">lm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(age, <span class="dv">5</span>), <span class="dt">data =</span> Wage)</span>
<span id="cb418-6"><a href="moving-beyond-linearity.html#cb418-6"></a><span class="kw">anova</span>(fit1, fit2, fit3, fit4, fit5)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: wage ~ poly(age, 1)
## Model 2: wage ~ poly(age, 2)
## Model 3: wage ~ poly(age, 3)
## Model 4: wage ~ poly(age, 4)
## Model 5: wage ~ poly(age, 5)
##   Res.Df     RSS Df Sum of Sq        F    Pr(&gt;F)    
## 1   2998 5022216                                    
## 2   2997 4793430  1    228786 143.5931 &lt; 2.2e-16 ***
## 3   2996 4777674  1     15756   9.8888  0.001679 ** 
## 4   2995 4771604  1      6070   3.8098  0.051046 .  
## 5   2994 4770322  1      1283   0.8050  0.369682    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The selected degree is 4. When testing with ANOVA, degrees 1, 2 and 3 are highly
significant and 4 is marginal.</p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Fit a step function to predict <code>wage</code> using <code>age</code>, and perform
cross-validation to choose the optimal number of cuts. Make a plot of the fit
obtained.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="moving-beyond-linearity.html#cb420-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb420-2"><a href="moving-beyond-linearity.html#cb420-2"></a>res &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">10</span>, <span class="cf">function</span>(i) {</span>
<span id="cb420-3"><a href="moving-beyond-linearity.html#cb420-3"></a>  Wage<span class="op">$</span>cats &lt;-<span class="st"> </span><span class="kw">cut</span>(Wage<span class="op">$</span>age, i)</span>
<span id="cb420-4"><a href="moving-beyond-linearity.html#cb420-4"></a>  fit &lt;-<span class="st"> </span><span class="kw">glm</span>(wage <span class="op">~</span><span class="st"> </span>cats, <span class="dt">data =</span> Wage)</span>
<span id="cb420-5"><a href="moving-beyond-linearity.html#cb420-5"></a>  <span class="kw">cv.glm</span>(Wage, fit, <span class="dt">K =</span> <span class="dv">5</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb420-6"><a href="moving-beyond-linearity.html#cb420-6"></a>})</span>
<span id="cb420-7"><a href="moving-beyond-linearity.html#cb420-7"></a><span class="kw">names</span>(res) &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">:</span><span class="dv">10</span></span>
<span id="cb420-8"><a href="moving-beyond-linearity.html#cb420-8"></a><span class="kw">plot</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">10</span>, res, <span class="dt">xlab =</span> <span class="st">&quot;Cuts&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Test MSE&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>)</span>
<span id="cb420-9"><a href="moving-beyond-linearity.html#cb420-9"></a><span class="kw">which.min</span>(res)</span></code></pre></div>
<pre><code>## 8 
## 7</code></pre>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="moving-beyond-linearity.html#cb422-1"></a><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">names</span>(<span class="kw">which.min</span>(res)), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="moving-beyond-linearity.html#cb423-1"></a>fit &lt;-<span class="st"> </span><span class="kw">glm</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">cut</span>(age, <span class="dv">8</span>), <span class="dt">data =</span> Wage)</span>
<span id="cb423-2"><a href="moving-beyond-linearity.html#cb423-2"></a><span class="kw">plot</span>(Wage<span class="op">$</span>age, Wage<span class="op">$</span>wage, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">0.4</span>, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>))</span>
<span id="cb423-3"><a href="moving-beyond-linearity.html#cb423-3"></a><span class="kw">points</span>(<span class="dv">18</span><span class="op">:</span><span class="dv">80</span>, <span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">age =</span> <span class="dv">18</span><span class="op">:</span><span class="dv">80</span>)), <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-4-2.png" width="672" /></p>
</div>
<div id="question-7-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.2</span> Question 7<a href="moving-beyond-linearity.html#question-7-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>The <code>Wage</code> data set contains a number of other features not explored in this
chapter, such as marital status (<code>maritl</code>), job class (<code>jobclass</code>), and others.
Explore the relationships between some of these other predictors and <code>wage</code>, and
use non-linear fitting techniques in order to fit flexible models to the data.
Create plots of the results obtained, and write a summary of your findings.</p>
</blockquote>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="moving-beyond-linearity.html#cb424-1"></a><span class="kw">plot</span>(Wage<span class="op">$</span>year, Wage<span class="op">$</span>wage, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">0.4</span>, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>))</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="moving-beyond-linearity.html#cb425-1"></a><span class="kw">plot</span>(Wage<span class="op">$</span>age, Wage<span class="op">$</span>wage, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">0.4</span>, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>))</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-5-2.png" width="672" /></p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="moving-beyond-linearity.html#cb426-1"></a><span class="kw">plot</span>(Wage<span class="op">$</span>maritl, Wage<span class="op">$</span>wage, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">0.4</span>, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>))</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-5-3.png" width="672" /></p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="moving-beyond-linearity.html#cb427-1"></a><span class="kw">plot</span>(Wage<span class="op">$</span>jobclass, Wage<span class="op">$</span>wage, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">0.4</span>, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>))</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-5-4.png" width="672" /></p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="moving-beyond-linearity.html#cb428-1"></a><span class="kw">plot</span>(Wage<span class="op">$</span>education, Wage<span class="op">$</span>wage, <span class="dt">pch =</span> <span class="dv">19</span>, <span class="dt">cex =</span> <span class="fl">0.4</span>, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>))</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-5-5.png" width="672" /></p>
<p>We have a mix of categorical and continuous variables and also want to
incorporate non-linear aspects of the continuous variables. A GAM is a good
choice to model this situation.</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="moving-beyond-linearity.html#cb429-1"></a><span class="kw">library</span>(gam)</span></code></pre></div>
<pre><code>## Loading required package: splines</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loaded gam 1.20.2</code></pre>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="moving-beyond-linearity.html#cb433-1"></a>fit0 &lt;-<span class="st"> </span><span class="kw">gam</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(year, <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(age, <span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>education, <span class="dt">data =</span> Wage)</span>
<span id="cb433-2"><a href="moving-beyond-linearity.html#cb433-2"></a>fit2 &lt;-<span class="st"> </span><span class="kw">gam</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(year, <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(age, <span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>maritl, <span class="dt">data =</span> Wage)</span>
<span id="cb433-3"><a href="moving-beyond-linearity.html#cb433-3"></a>fit1 &lt;-<span class="st"> </span><span class="kw">gam</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(year, <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(age, <span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>jobclass, <span class="dt">data =</span> Wage)</span>
<span id="cb433-4"><a href="moving-beyond-linearity.html#cb433-4"></a>fit3 &lt;-<span class="st"> </span><span class="kw">gam</span>(wage <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(year, <span class="dv">4</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(age, <span class="dv">5</span>) <span class="op">+</span><span class="st"> </span>education <span class="op">+</span><span class="st"> </span>jobclass <span class="op">+</span><span class="st"> </span>maritl, <span class="dt">data =</span> Wage)</span>
<span id="cb433-5"><a href="moving-beyond-linearity.html#cb433-5"></a><span class="kw">anova</span>(fit0, fit1, fit2, fit3)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: wage ~ s(year, 4) + s(age, 5) + education
## Model 2: wage ~ s(year, 4) + s(age, 5) + education + jobclass
## Model 3: wage ~ s(year, 4) + s(age, 5) + education + maritl
## Model 4: wage ~ s(year, 4) + s(age, 5) + education + jobclass + maritl
##   Resid. Df Resid. Dev Df Deviance  Pr(&gt;Chi)    
## 1      2986    3689770                          
## 2      2985    3677553  1    12218 0.0014286 ** 
## 3      2982    3595688  3    81865 1.071e-14 ***
## 4      2981    3581781  1    13907 0.0006687 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="moving-beyond-linearity.html#cb435-1"></a><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">3</span>))</span>
<span id="cb435-2"><a href="moving-beyond-linearity.html#cb435-2"></a><span class="kw">plot</span>(fit3, <span class="dt">se =</span> <span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="question-8-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.3</span> Question 8<a href="moving-beyond-linearity.html#question-8-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Fit some of the non-linear models investigated in this chapter to the <code>Auto</code>
data set. Is there evidence for non-linear relationships in this data set?
Create some informative plots to justify your answer.</p>
</blockquote>
<p>Here we want to explore a range of non-linear models. First let’s look at the
relationships between the variables in the data.</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="moving-beyond-linearity.html#cb436-1"></a><span class="kw">pairs</span>(Auto, <span class="dt">cex =</span> <span class="fl">0.4</span>, <span class="dt">pch =</span> <span class="dv">19</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>It does appear that there are some non-linear relationships (e.g.
horsepower / weight and mpg). We will pick one variable (horsepower) to predict
mpg and try the range of models discussed in this chapter. We will measure
test MSE through cross-validation to compare the models.</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="moving-beyond-linearity.html#cb437-1"></a><span class="kw">library</span>(tidyverse)</span></code></pre></div>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
## ✔ tidyr   1.2.1      ✔ stringr 1.4.1 
## ✔ readr   2.1.3      ✔ forcats 0.5.2 
## ✔ purrr   0.3.5      
## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ purrr::accumulate() masks foreach::accumulate()
## ✖ dplyr::filter()     masks stats::filter()
## ✖ dplyr::lag()        masks stats::lag()
## ✖ purrr::when()       masks foreach::when()</code></pre>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="moving-beyond-linearity.html#cb439-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb439-2"><a href="moving-beyond-linearity.html#cb439-2"></a>fit &lt;-<span class="st"> </span><span class="kw">glm</span>(mpg <span class="op">~</span><span class="st"> </span>horsepower, <span class="dt">data =</span> Auto)</span>
<span id="cb439-3"><a href="moving-beyond-linearity.html#cb439-3"></a>err &lt;-<span class="st"> </span><span class="kw">cv.glm</span>(Auto, fit, <span class="dt">K =</span> <span class="dv">10</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb439-4"><a href="moving-beyond-linearity.html#cb439-4"></a></span>
<span id="cb439-5"><a href="moving-beyond-linearity.html#cb439-5"></a>fit1 &lt;-<span class="st"> </span><span class="kw">glm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(horsepower, <span class="dv">4</span>), <span class="dt">data =</span> Auto)</span>
<span id="cb439-6"><a href="moving-beyond-linearity.html#cb439-6"></a>err1 &lt;-<span class="st"> </span><span class="kw">cv.glm</span>(Auto, fit1, <span class="dt">K =</span> <span class="dv">10</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb439-7"><a href="moving-beyond-linearity.html#cb439-7"></a></span>
<span id="cb439-8"><a href="moving-beyond-linearity.html#cb439-8"></a>q &lt;-<span class="st"> </span><span class="kw">quantile</span>(Auto<span class="op">$</span>horsepower)</span>
<span id="cb439-9"><a href="moving-beyond-linearity.html#cb439-9"></a>Auto<span class="op">$</span>hp_cats &lt;-<span class="st"> </span><span class="kw">cut</span>(Auto<span class="op">$</span>horsepower, <span class="dt">breaks =</span> q, <span class="dt">include.lowest =</span> <span class="ot">TRUE</span>)</span>
<span id="cb439-10"><a href="moving-beyond-linearity.html#cb439-10"></a>fit2 &lt;-<span class="st"> </span><span class="kw">glm</span>(mpg <span class="op">~</span><span class="st"> </span>hp_cats, <span class="dt">data =</span> Auto)</span>
<span id="cb439-11"><a href="moving-beyond-linearity.html#cb439-11"></a>err2 &lt;-<span class="st"> </span><span class="kw">cv.glm</span>(Auto, fit2, <span class="dt">K =</span> <span class="dv">10</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb439-12"><a href="moving-beyond-linearity.html#cb439-12"></a></span>
<span id="cb439-13"><a href="moving-beyond-linearity.html#cb439-13"></a>fit3 &lt;-<span class="st"> </span><span class="kw">glm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">bs</span>(horsepower, <span class="dt">df =</span> <span class="dv">4</span>), <span class="dt">data =</span> Auto)</span>
<span id="cb439-14"><a href="moving-beyond-linearity.html#cb439-14"></a>err3 &lt;-<span class="st"> </span><span class="kw">cv.glm</span>(Auto, fit3, <span class="dt">K =</span> <span class="dv">10</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</span></code></pre></div>
<pre><code>## Warning in bs(horsepower, degree = 3L, knots = c(`50%` = 92), Boundary.knots =
## c(46L, : some &#39;x&#39; values beyond boundary knots may cause ill-conditioned bases

## Warning in bs(horsepower, degree = 3L, knots = c(`50%` = 92), Boundary.knots =
## c(46L, : some &#39;x&#39; values beyond boundary knots may cause ill-conditioned bases</code></pre>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="moving-beyond-linearity.html#cb441-1"></a>fit4 &lt;-<span class="st"> </span><span class="kw">glm</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">ns</span>(horsepower, <span class="dv">4</span>), <span class="dt">data =</span> Auto)</span>
<span id="cb441-2"><a href="moving-beyond-linearity.html#cb441-2"></a>err4 &lt;-<span class="st"> </span><span class="kw">cv.glm</span>(Auto, fit4, <span class="dt">K =</span> <span class="dv">10</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb441-3"><a href="moving-beyond-linearity.html#cb441-3"></a></span>
<span id="cb441-4"><a href="moving-beyond-linearity.html#cb441-4"></a>fit5 &lt;-<span class="st"> </span><span class="kw">gam</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(horsepower, <span class="dt">df =</span> <span class="dv">4</span>), <span class="dt">data =</span> Auto)</span>
<span id="cb441-5"><a href="moving-beyond-linearity.html#cb441-5"></a><span class="co"># rough 10-fold cross-validation for gam.</span></span>
<span id="cb441-6"><a href="moving-beyond-linearity.html#cb441-6"></a>err5 &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">replicate</span>(<span class="dv">10</span>, {</span>
<span id="cb441-7"><a href="moving-beyond-linearity.html#cb441-7"></a>  b &lt;-<span class="st"> </span><span class="kw">cut</span>(<span class="kw">sample</span>(<span class="kw">seq_along</span>(Auto<span class="op">$</span>horsepower)), <span class="dv">10</span>)</span>
<span id="cb441-8"><a href="moving-beyond-linearity.html#cb441-8"></a>  pred &lt;-<span class="st"> </span><span class="kw">numeric</span>()</span>
<span id="cb441-9"><a href="moving-beyond-linearity.html#cb441-9"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) {</span>
<span id="cb441-10"><a href="moving-beyond-linearity.html#cb441-10"></a>    train &lt;-<span class="st"> </span>b <span class="op">%in%</span><span class="st"> </span><span class="kw">levels</span>(b)[<span class="op">-</span>i]</span>
<span id="cb441-11"><a href="moving-beyond-linearity.html#cb441-11"></a>    f &lt;-<span class="st"> </span><span class="kw">gam</span>(mpg <span class="op">~</span><span class="st"> </span><span class="kw">s</span>(horsepower, <span class="dt">df =</span> <span class="dv">4</span>), <span class="dt">data =</span> Auto[train, ])</span>
<span id="cb441-12"><a href="moving-beyond-linearity.html#cb441-12"></a>    pred[<span class="op">!</span>train] &lt;-<span class="st"> </span><span class="kw">predict</span>(f, Auto[<span class="op">!</span>train, ])</span>
<span id="cb441-13"><a href="moving-beyond-linearity.html#cb441-13"></a>  }</span>
<span id="cb441-14"><a href="moving-beyond-linearity.html#cb441-14"></a>  <span class="kw">mean</span>((Auto<span class="op">$</span>mpg <span class="op">-</span><span class="st"> </span>pred)<span class="op">^</span><span class="dv">2</span>) <span class="co"># MSE</span></span>
<span id="cb441-15"><a href="moving-beyond-linearity.html#cb441-15"></a>}))</span>
<span id="cb441-16"><a href="moving-beyond-linearity.html#cb441-16"></a></span>
<span id="cb441-17"><a href="moving-beyond-linearity.html#cb441-17"></a><span class="kw">c</span>(err, err1, err2, err3, err4, err5)</span></code></pre></div>
<pre><code>## [1] 24.38418 19.94222 20.37940 18.92802 19.33556 19.02999</code></pre>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="moving-beyond-linearity.html#cb443-1"></a><span class="kw">anova</span>(fit, fit1, fit2, fit3, fit4, fit5)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: mpg ~ horsepower
## Model 2: mpg ~ poly(horsepower, 4)
## Model 3: mpg ~ hp_cats
## Model 4: mpg ~ bs(horsepower, df = 4)
## Model 5: mpg ~ ns(horsepower, 4)
## Model 6: mpg ~ s(horsepower, df = 4)
##   Resid. Df Resid. Dev          Df Deviance
## 1       390     9385.9                     
## 2       387     7399.5  3.00000000  1986.39
## 3       388     7805.4 -1.00000000  -405.92
## 4       387     7276.5  1.00000000   528.94
## 5       387     7248.6  0.00000000    27.91
## 6       387     7267.7  0.00013612   -19.10</code></pre>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="moving-beyond-linearity.html#cb445-1"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(Auto<span class="op">$</span>horsepower), <span class="kw">max</span>(Auto<span class="op">$</span>horsepower), <span class="dt">length.out=</span><span class="dv">1000</span>)</span>
<span id="cb445-2"><a href="moving-beyond-linearity.html#cb445-2"></a>pred &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb445-3"><a href="moving-beyond-linearity.html#cb445-3"></a>  <span class="dt">x =</span> x,</span>
<span id="cb445-4"><a href="moving-beyond-linearity.html#cb445-4"></a>  <span class="st">&quot;Linear&quot;</span> =<span class="st"> </span><span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">horsepower =</span> x)),</span>
<span id="cb445-5"><a href="moving-beyond-linearity.html#cb445-5"></a>  <span class="st">&quot;Polynomial&quot;</span> =<span class="st"> </span><span class="kw">predict</span>(fit1, <span class="kw">data.frame</span>(<span class="dt">horsepower =</span> x)),</span>
<span id="cb445-6"><a href="moving-beyond-linearity.html#cb445-6"></a>  <span class="st">&quot;Step&quot;</span> =<span class="st"> </span><span class="kw">predict</span>(fit2, <span class="kw">data.frame</span>(<span class="dt">hp_cats =</span> <span class="kw">cut</span>(x, <span class="dt">breaks =</span> q, <span class="dt">include.lowest =</span> <span class="ot">TRUE</span>))),</span>
<span id="cb445-7"><a href="moving-beyond-linearity.html#cb445-7"></a>  <span class="st">&quot;Regression spline&quot;</span> =<span class="st"> </span><span class="kw">predict</span>(fit3, <span class="kw">data.frame</span>(<span class="dt">horsepower =</span> x)),</span>
<span id="cb445-8"><a href="moving-beyond-linearity.html#cb445-8"></a>  <span class="st">&quot;Natural spline&quot;</span> =<span class="st"> </span><span class="kw">predict</span>(fit4, <span class="kw">data.frame</span>(<span class="dt">horsepower =</span> x)),</span>
<span id="cb445-9"><a href="moving-beyond-linearity.html#cb445-9"></a>  <span class="st">&quot;Smoothing spline&quot;</span> =<span class="st"> </span><span class="kw">predict</span>(fit5, <span class="kw">data.frame</span>(<span class="dt">horsepower =</span> x)),</span>
<span id="cb445-10"><a href="moving-beyond-linearity.html#cb445-10"></a>  <span class="dt">check.names =</span> <span class="ot">FALSE</span></span>
<span id="cb445-11"><a href="moving-beyond-linearity.html#cb445-11"></a>)</span>
<span id="cb445-12"><a href="moving-beyond-linearity.html#cb445-12"></a>pred &lt;-<span class="st"> </span><span class="kw">pivot_longer</span>(pred, <span class="op">-</span>x)</span>
<span id="cb445-13"><a href="moving-beyond-linearity.html#cb445-13"></a><span class="kw">ggplot</span>(Auto, <span class="kw">aes</span>(horsepower, mpg)) <span class="op">+</span></span>
<span id="cb445-14"><a href="moving-beyond-linearity.html#cb445-14"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>)) <span class="op">+</span></span>
<span id="cb445-15"><a href="moving-beyond-linearity.html#cb445-15"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> pred, <span class="kw">aes</span>(x, value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb445-16"><a href="moving-beyond-linearity.html#cb445-16"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="question-9-5" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.4</span> Question 9<a href="moving-beyond-linearity.html#question-9-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>This question uses the variables <code>dis</code> (the weighted mean of distances to five
Boston employment centers) and <code>nox</code> (nitrogen oxides concentration in parts per
10 million) from the <code>Boston</code> data. We will treat <code>dis</code> as the predictor and
<code>nox</code> as the response.</p>
<ol style="list-style-type: lower-alpha">
<li>Use the <code>poly()</code> function to fit a cubic polynomial regression to predict
<code>nox</code> using <code>dis</code>. Report the regression output, and plot the resulting data
and polynomial fits.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="moving-beyond-linearity.html#cb446-1"></a>fit &lt;-<span class="st"> </span><span class="kw">glm</span>(nox <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(dis, <span class="dv">3</span>), <span class="dt">data =</span> Boston)</span>
<span id="cb446-2"><a href="moving-beyond-linearity.html#cb446-2"></a><span class="kw">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = nox ~ poly(dis, 3), data = Boston)
## 
## Deviance Residuals: 
##       Min         1Q     Median         3Q        Max  
## -0.121130  -0.040619  -0.009738   0.023385   0.194904  
## 
## Coefficients:
##                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    0.554695   0.002759 201.021  &lt; 2e-16 ***
## poly(dis, 3)1 -2.003096   0.062071 -32.271  &lt; 2e-16 ***
## poly(dis, 3)2  0.856330   0.062071  13.796  &lt; 2e-16 ***
## poly(dis, 3)3 -0.318049   0.062071  -5.124 4.27e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 0.003852802)
## 
##     Null deviance: 6.7810  on 505  degrees of freedom
## Residual deviance: 1.9341  on 502  degrees of freedom
## AIC: -1370.9
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="moving-beyond-linearity.html#cb448-1"></a><span class="kw">plot</span>(nox <span class="op">~</span><span class="st"> </span>dis, <span class="dt">data =</span> Boston, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>), <span class="dt">pch =</span> <span class="dv">19</span>)</span>
<span id="cb448-2"><a href="moving-beyond-linearity.html#cb448-2"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(Boston<span class="op">$</span>dis), <span class="kw">max</span>(Boston<span class="op">$</span>dis), <span class="dt">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb448-3"><a href="moving-beyond-linearity.html#cb448-3"></a><span class="kw">lines</span>(x, <span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">dis =</span> x)), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Plot the polynomial fits for a range of different polynomial degrees (say,
from 1 to 10), and report the associated residual sum of squares.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb449"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb449-1"><a href="moving-beyond-linearity.html#cb449-1"></a>fits &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="cf">function</span>(i) <span class="kw">glm</span>(nox <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(dis, i), <span class="dt">data =</span> Boston))</span>
<span id="cb449-2"><a href="moving-beyond-linearity.html#cb449-2"></a></span>
<span id="cb449-3"><a href="moving-beyond-linearity.html#cb449-3"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(Boston<span class="op">$</span>dis), <span class="kw">max</span>(Boston<span class="op">$</span>dis), <span class="dt">length.out=</span><span class="dv">1000</span>)</span>
<span id="cb449-4"><a href="moving-beyond-linearity.html#cb449-4"></a>pred &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">lapply</span>(fits, <span class="cf">function</span>(fit) <span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">dis =</span> x))))</span>
<span id="cb449-5"><a href="moving-beyond-linearity.html#cb449-5"></a><span class="kw">colnames</span>(pred) &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">10</span></span>
<span id="cb449-6"><a href="moving-beyond-linearity.html#cb449-6"></a>pred<span class="op">$</span>x &lt;-<span class="st"> </span>x</span>
<span id="cb449-7"><a href="moving-beyond-linearity.html#cb449-7"></a>pred &lt;-<span class="st"> </span><span class="kw">pivot_longer</span>(pred, <span class="op">!</span>x)</span>
<span id="cb449-8"><a href="moving-beyond-linearity.html#cb449-8"></a><span class="kw">ggplot</span>(Boston, <span class="kw">aes</span>(dis, nox)) <span class="op">+</span></span>
<span id="cb449-9"><a href="moving-beyond-linearity.html#cb449-9"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>)) <span class="op">+</span></span>
<span id="cb449-10"><a href="moving-beyond-linearity.html#cb449-10"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> pred, <span class="kw">aes</span>(x, value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb449-11"><a href="moving-beyond-linearity.html#cb449-11"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="moving-beyond-linearity.html#cb450-1"></a><span class="co"># residual sum of squares</span></span>
<span id="cb450-2"><a href="moving-beyond-linearity.html#cb450-2"></a><span class="kw">do.call</span>(anova, fits)[, <span class="dv">2</span>]</span></code></pre></div>
<pre><code>##  [1] 2.768563 2.035262 1.934107 1.932981 1.915290 1.878257 1.849484 1.835630
##  [9] 1.833331 1.832171</code></pre>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Perform cross-validation or another approach to select the optimal degree
for the polynomial, and explain your results.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="moving-beyond-linearity.html#cb452-1"></a>res &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="cf">function</span>(i) {</span>
<span id="cb452-2"><a href="moving-beyond-linearity.html#cb452-2"></a>  fit &lt;-<span class="st"> </span><span class="kw">glm</span>(nox <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(dis, i), <span class="dt">data =</span> Boston)</span>
<span id="cb452-3"><a href="moving-beyond-linearity.html#cb452-3"></a>  <span class="kw">cv.glm</span>(Boston, fit, <span class="dt">K =</span> <span class="dv">10</span>)<span class="op">$</span>delta[<span class="dv">1</span>]</span>
<span id="cb452-4"><a href="moving-beyond-linearity.html#cb452-4"></a>})</span>
<span id="cb452-5"><a href="moving-beyond-linearity.html#cb452-5"></a><span class="kw">which.min</span>(res)</span></code></pre></div>
<pre><code>## [1] 4</code></pre>
<p>The optimal degree is 3 based on cross-validation. Higher values tend to
lead to overfitting.</p>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>Use the <code>bs()</code> function to fit a regression spline to predict <code>nox</code> using
<code>dis</code>. Report the output for the fit using four degrees of freedom. How did
you choose the knots? Plot the resulting fit.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="moving-beyond-linearity.html#cb454-1"></a>fit &lt;-<span class="st"> </span><span class="kw">glm</span>(nox <span class="op">~</span><span class="st"> </span><span class="kw">bs</span>(dis, <span class="dt">df =</span> <span class="dv">4</span>), <span class="dt">data =</span> Boston)</span>
<span id="cb454-2"><a href="moving-beyond-linearity.html#cb454-2"></a><span class="kw">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = nox ~ bs(dis, df = 4), data = Boston)
## 
## Deviance Residuals: 
##       Min         1Q     Median         3Q        Max  
## -0.124622  -0.039259  -0.008514   0.020850   0.193891  
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       0.73447    0.01460  50.306  &lt; 2e-16 ***
## bs(dis, df = 4)1 -0.05810    0.02186  -2.658  0.00812 ** 
## bs(dis, df = 4)2 -0.46356    0.02366 -19.596  &lt; 2e-16 ***
## bs(dis, df = 4)3 -0.19979    0.04311  -4.634 4.58e-06 ***
## bs(dis, df = 4)4 -0.38881    0.04551  -8.544  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 0.003837874)
## 
##     Null deviance: 6.7810  on 505  degrees of freedom
## Residual deviance: 1.9228  on 501  degrees of freedom
## AIC: -1371.9
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="moving-beyond-linearity.html#cb456-1"></a><span class="kw">plot</span>(nox <span class="op">~</span><span class="st"> </span>dis, <span class="dt">data =</span> Boston, <span class="dt">col =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>), <span class="dt">pch =</span> <span class="dv">19</span>)</span>
<span id="cb456-2"><a href="moving-beyond-linearity.html#cb456-2"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(Boston<span class="op">$</span>dis), <span class="kw">max</span>(Boston<span class="op">$</span>dis), <span class="dt">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb456-3"><a href="moving-beyond-linearity.html#cb456-3"></a><span class="kw">lines</span>(x, <span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">dis =</span> x)), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Knots are chosen based on quantiles of the data.</p>
<blockquote>
<ol start="5" style="list-style-type: lower-alpha">
<li>Now fit a regression spline for a range of degrees of freedom, and plot the
resulting fits and report the resulting RSS. Describe the results obtained.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="moving-beyond-linearity.html#cb457-1"></a>fits &lt;-<span class="st"> </span><span class="kw">lapply</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">10</span>, <span class="cf">function</span>(i) {</span>
<span id="cb457-2"><a href="moving-beyond-linearity.html#cb457-2"></a>  <span class="kw">glm</span>(nox <span class="op">~</span><span class="st"> </span><span class="kw">bs</span>(dis, <span class="dt">df =</span> i), <span class="dt">data =</span> Boston)</span>
<span id="cb457-3"><a href="moving-beyond-linearity.html#cb457-3"></a>})</span>
<span id="cb457-4"><a href="moving-beyond-linearity.html#cb457-4"></a></span>
<span id="cb457-5"><a href="moving-beyond-linearity.html#cb457-5"></a>x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="kw">min</span>(Boston<span class="op">$</span>dis), <span class="kw">max</span>(Boston<span class="op">$</span>dis), <span class="dt">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb457-6"><a href="moving-beyond-linearity.html#cb457-6"></a>pred &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="kw">lapply</span>(fits, <span class="cf">function</span>(fit) <span class="kw">predict</span>(fit, <span class="kw">data.frame</span>(<span class="dt">dis =</span> x))))</span>
<span id="cb457-7"><a href="moving-beyond-linearity.html#cb457-7"></a><span class="kw">colnames</span>(pred) &lt;-<span class="st"> </span><span class="dv">3</span><span class="op">:</span><span class="dv">10</span></span>
<span id="cb457-8"><a href="moving-beyond-linearity.html#cb457-8"></a>pred<span class="op">$</span>x &lt;-<span class="st"> </span>x</span>
<span id="cb457-9"><a href="moving-beyond-linearity.html#cb457-9"></a>pred &lt;-<span class="st"> </span><span class="kw">pivot_longer</span>(pred, <span class="op">!</span>x)</span>
<span id="cb457-10"><a href="moving-beyond-linearity.html#cb457-10"></a><span class="kw">ggplot</span>(Boston, <span class="kw">aes</span>(dis, nox)) <span class="op">+</span></span>
<span id="cb457-11"><a href="moving-beyond-linearity.html#cb457-11"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">color =</span> <span class="kw">alpha</span>(<span class="st">&quot;steelblue&quot;</span>, <span class="fl">0.4</span>)) <span class="op">+</span></span>
<span id="cb457-12"><a href="moving-beyond-linearity.html#cb457-12"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="dt">data =</span> pred, <span class="kw">aes</span>(x, value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb457-13"><a href="moving-beyond-linearity.html#cb457-13"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>At high numbers of degrees of freedom the splines overfit the data (particularly
at extreme ends of the distribution of the predictor variable).</p>
<blockquote>
<ol start="6" style="list-style-type: lower-alpha">
<li>Perform cross-validation or another approach in order to select the best
degrees of freedom for a regression spline on this data. Describe your
results.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="moving-beyond-linearity.html#cb458-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb458-2"><a href="moving-beyond-linearity.html#cb458-2"></a>err &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">10</span>, <span class="cf">function</span>(i) {</span>
<span id="cb458-3"><a href="moving-beyond-linearity.html#cb458-3"></a>  fit &lt;-<span class="st"> </span><span class="kw">glm</span>(nox <span class="op">~</span><span class="st"> </span><span class="kw">bs</span>(dis, <span class="dt">df =</span> i), <span class="dt">data =</span> Boston)</span>
<span id="cb458-4"><a href="moving-beyond-linearity.html#cb458-4"></a>  <span class="kw">suppressWarnings</span>(<span class="kw">cv.glm</span>(Boston, fit, <span class="dt">K =</span> <span class="dv">10</span>)<span class="op">$</span>delta[<span class="dv">1</span>])</span>
<span id="cb458-5"><a href="moving-beyond-linearity.html#cb458-5"></a>})</span>
<span id="cb458-6"><a href="moving-beyond-linearity.html#cb458-6"></a><span class="kw">which.min</span>(err)</span></code></pre></div>
<pre><code>## [1] 8</code></pre>
<p>This approach would select 4 degrees of freedom for the spline.</p>
</div>
<div id="question-10-4" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.5</span> Question 10<a href="moving-beyond-linearity.html#question-10-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>This question relates to the <code>College</code> data set.</p>
<ol style="list-style-type: lower-alpha">
<li>Split the data into a training set and a test set. Using out-of-state tuition
as the response and the other variables as the predictors, perform forward
stepwise selection on the training set in order to identify a satisfactory
model that uses just a subset of the predictors.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="moving-beyond-linearity.html#cb460-1"></a><span class="kw">library</span>(leaps)</span>
<span id="cb460-2"><a href="moving-beyond-linearity.html#cb460-2"></a></span>
<span id="cb460-3"><a href="moving-beyond-linearity.html#cb460-3"></a><span class="co"># helper function to predict from a regsubsets model</span></span>
<span id="cb460-4"><a href="moving-beyond-linearity.html#cb460-4"></a>predict.regsubsets &lt;-<span class="st"> </span><span class="cf">function</span>(object, newdata, id, ...) {</span>
<span id="cb460-5"><a href="moving-beyond-linearity.html#cb460-5"></a>  form &lt;-<span class="st"> </span><span class="kw">as.formula</span>(object<span class="op">$</span>call[[<span class="dv">2</span>]])</span>
<span id="cb460-6"><a href="moving-beyond-linearity.html#cb460-6"></a>  mat &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(form, newdata)</span>
<span id="cb460-7"><a href="moving-beyond-linearity.html#cb460-7"></a>  coefi &lt;-<span class="st"> </span><span class="kw">coef</span>(object, <span class="dt">id =</span> id)</span>
<span id="cb460-8"><a href="moving-beyond-linearity.html#cb460-8"></a>  xvars &lt;-<span class="st"> </span><span class="kw">names</span>(coefi)</span>
<span id="cb460-9"><a href="moving-beyond-linearity.html#cb460-9"></a>  mat[, xvars] <span class="op">%*%</span><span class="st"> </span>coefi</span>
<span id="cb460-10"><a href="moving-beyond-linearity.html#cb460-10"></a>}</span>
<span id="cb460-11"><a href="moving-beyond-linearity.html#cb460-11"></a></span>
<span id="cb460-12"><a href="moving-beyond-linearity.html#cb460-12"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb460-13"><a href="moving-beyond-linearity.html#cb460-13"></a>train &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">TRUE</span>, <span class="kw">nrow</span>(College))</span>
<span id="cb460-14"><a href="moving-beyond-linearity.html#cb460-14"></a>train[<span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(College), <span class="kw">nrow</span>(College) <span class="op">*</span><span class="st"> </span><span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">3</span>)] &lt;-<span class="st"> </span><span class="ot">FALSE</span></span>
<span id="cb460-15"><a href="moving-beyond-linearity.html#cb460-15"></a>fit &lt;-<span class="st"> </span><span class="kw">regsubsets</span>(Outstate <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> College[train, ], <span class="dt">nvmax =</span> <span class="dv">17</span>, <span class="dt">method =</span> <span class="st">&quot;forward&quot;</span>)</span>
<span id="cb460-16"><a href="moving-beyond-linearity.html#cb460-16"></a></span>
<span id="cb460-17"><a href="moving-beyond-linearity.html#cb460-17"></a><span class="kw">plot</span>(<span class="kw">summary</span>(fit)<span class="op">$</span>bic, <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="moving-beyond-linearity.html#cb461-1"></a><span class="kw">which.min</span>(<span class="kw">summary</span>(fit)<span class="op">$</span>bic)</span></code></pre></div>
<pre><code>## [1] 11</code></pre>
<div class="sourceCode" id="cb463"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb463-1"><a href="moving-beyond-linearity.html#cb463-1"></a><span class="co"># or via cross-validation</span></span>
<span id="cb463-2"><a href="moving-beyond-linearity.html#cb463-2"></a>err &lt;-<span class="st"> </span><span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">17</span>, <span class="cf">function</span>(i) {</span>
<span id="cb463-3"><a href="moving-beyond-linearity.html#cb463-3"></a>  x &lt;-<span class="st"> </span><span class="kw">coef</span>(fit, <span class="dt">id =</span> i)</span>
<span id="cb463-4"><a href="moving-beyond-linearity.html#cb463-4"></a>  <span class="kw">mean</span>((College<span class="op">$</span>Outstate[<span class="op">!</span>train] <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(fit, College[<span class="op">!</span>train, ], i))<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb463-5"><a href="moving-beyond-linearity.html#cb463-5"></a>})</span>
<span id="cb463-6"><a href="moving-beyond-linearity.html#cb463-6"></a><span class="kw">which.min</span>(err)</span></code></pre></div>
<pre><code>## [1] 16</code></pre>
<div class="sourceCode" id="cb465"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb465-1"><a href="moving-beyond-linearity.html#cb465-1"></a><span class="kw">min</span>(<span class="kw">summary</span>(fit)<span class="op">$</span>bic)</span></code></pre></div>
<pre><code>## [1] -690.9375</code></pre>
<p>For the sake of simplicity we’ll choose 6</p>
<div class="sourceCode" id="cb467"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb467-1"><a href="moving-beyond-linearity.html#cb467-1"></a><span class="kw">coef</span>(fit, <span class="dt">id =</span> <span class="dv">6</span>)</span></code></pre></div>
<pre><code>##   (Intercept)    PrivateYes    Room.Board           PhD   perc.alumni 
## -3540.0544008  2736.4231642     0.9061752    33.7848157    47.1998115 
##        Expend     Grad.Rate 
##     0.2421685    33.3137332</code></pre>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Fit a GAM on the training data, using out-of-state tuition as the response
and the features selected in the previous step as the predictors. Plot the
results, and explain your findings.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb469"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb469-1"><a href="moving-beyond-linearity.html#cb469-1"></a>fit &lt;-<span class="st"> </span><span class="kw">gam</span>(Outstate <span class="op">~</span><span class="st"> </span>Private <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(Room.Board, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(PhD, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(perc.alumni, <span class="dv">2</span>) <span class="op">+</span></span>
<span id="cb469-2"><a href="moving-beyond-linearity.html#cb469-2"></a><span class="st">  </span><span class="kw">s</span>(Expend, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">s</span>(Grad.Rate, <span class="dv">2</span>), <span class="dt">data =</span> College[train, ])</span></code></pre></div>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Evaluate the model obtained on the test set, and explain the results
obtained.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb470"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb470-1"><a href="moving-beyond-linearity.html#cb470-1"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, College[<span class="op">!</span>train, ])</span>
<span id="cb470-2"><a href="moving-beyond-linearity.html#cb470-2"></a>err_gam &lt;-<span class="st"> </span><span class="kw">mean</span>((College<span class="op">$</span>Outstate[<span class="op">!</span>train] <span class="op">-</span><span class="st"> </span>pred)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb470-3"><a href="moving-beyond-linearity.html#cb470-3"></a><span class="kw">plot</span>(err, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="kw">min</span>(err_gam, err), <span class="kw">max</span>(err)), <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>)</span>
<span id="cb470-4"><a href="moving-beyond-linearity.html#cb470-4"></a><span class="kw">abline</span>(<span class="dt">h =</span> err_gam, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<div class="sourceCode" id="cb471"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb471-1"><a href="moving-beyond-linearity.html#cb471-1"></a><span class="co"># r-squared</span></span>
<span id="cb471-2"><a href="moving-beyond-linearity.html#cb471-2"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>err_gam <span class="op">/</span><span class="st"> </span><span class="kw">mean</span>((College<span class="op">$</span>Outstate[<span class="op">!</span>train] <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(College<span class="op">$</span>Outstate[<span class="op">!</span>train]))<span class="op">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.7655905</code></pre>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>For which variables, if any, is there evidence of a non-linear relationship
with the response?</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb473"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb473-1"><a href="moving-beyond-linearity.html#cb473-1"></a><span class="kw">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call: gam(formula = Outstate ~ Private + s(Room.Board, 2) + s(PhD, 
##     2) + s(perc.alumni, 2) + s(Expend, 2) + s(Grad.Rate, 2), 
##     data = College[train, ])
## Deviance Residuals:
##      Min       1Q   Median       3Q      Max 
## -7112.59 -1188.98    33.13  1238.54  8738.65 
## 
## (Dispersion Parameter for gaussian family taken to be 3577008)
## 
##     Null Deviance: 8471793308 on 517 degrees of freedom
## Residual Deviance: 1809966249 on 506.0001 degrees of freedom
## AIC: 9300.518 
## 
## Number of Local Scoring Iterations: NA 
## 
## Anova for Parametric Effects
##                    Df     Sum Sq    Mean Sq F value    Pr(&gt;F)    
## Private             1 2327235738 2327235738 650.610 &lt; 2.2e-16 ***
## s(Room.Board, 2)    1 1741918028 1741918028 486.976 &lt; 2.2e-16 ***
## s(PhD, 2)           1  668408518  668408518 186.863 &lt; 2.2e-16 ***
## s(perc.alumni, 2)   1  387819183  387819183 108.420 &lt; 2.2e-16 ***
## s(Expend, 2)        1  625813340  625813340 174.954 &lt; 2.2e-16 ***
## s(Grad.Rate, 2)     1  111881207  111881207  31.278 3.664e-08 ***
## Residuals         506 1809966249    3577008                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Anova for Nonparametric Effects
##                   Npar Df Npar F     Pr(F)    
## (Intercept)                                   
## Private                                       
## s(Room.Board, 2)        1  2.224   0.13648    
## s(PhD, 2)               1  5.773   0.01664 *  
## s(perc.alumni, 2)       1  0.365   0.54581    
## s(Expend, 2)            1 61.182 3.042e-14 ***
## s(Grad.Rate, 2)         1  4.126   0.04274 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Non-linear relationships are significant for Expend and PhD.</p>
</div>
<div id="question-11-3" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.6</span> Question 11<a href="moving-beyond-linearity.html#question-11-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>In Section 7.7, it was mentioned that GAMs are generally fit using a
<em>backfitting</em> approach. The idea behind backfitting is actually quite simple. We
will now explore backfitting in the context of multiple linear regression.</p>
<p>Suppose that we would like to perform multiple linear regression, but we do not
have software to do so. Instead, we only have software to perform simple linear
regression. Therefore, we take the following iterative approach: we repeatedly
hold all but one coefficient estimate fixed at its current value, and update
only that coefficient estimate using a simple linear regression. The process is
continued until <em>convergence</em>—that is, until the coefficient estimates stop
changing.</p>
<p>We now try this out on a toy example.</p>
<ol style="list-style-type: lower-alpha">
<li>Generate a response <span class="math inline">\(Y\)</span> and two predictors <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, with <span class="math inline">\(n = 100\)</span>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb475"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb475-1"><a href="moving-beyond-linearity.html#cb475-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb475-2"><a href="moving-beyond-linearity.html#cb475-2"></a>x1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb475-3"><a href="moving-beyond-linearity.html#cb475-3"></a>x2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb475-4"><a href="moving-beyond-linearity.html#cb475-4"></a>y &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.2</span> <span class="op">*</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span><span class="dv">4</span> <span class="op">*</span><span class="st"> </span>x2 <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)</span></code></pre></div>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Initialize <span class="math inline">\(\hat{\beta}_1\)</span> to take on a value of your choice. It does not
matter 1 what value you choose.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb476"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb476-1"><a href="moving-beyond-linearity.html#cb476-1"></a>beta1 &lt;-<span class="st"> </span><span class="dv">20</span></span></code></pre></div>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li><p>Keeping <span class="math inline">\(\hat{\beta}_1\)</span> fixed, fit the model
<span class="math display">\[Y - \hat{\beta}_1X_1 = \beta_0 + \beta_2X_2 + \epsilon.\]</span>
You can do this as follows:</p>
<div class="sourceCode" id="cb477"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb477-1"><a href="moving-beyond-linearity.html#cb477-1"></a><span class="op">&gt;</span><span class="st"> </span>a &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>beta1 <span class="op">*</span><span class="st"> </span>x1</span>
<span id="cb477-2"><a href="moving-beyond-linearity.html#cb477-2"></a><span class="op">&gt;</span><span class="st"> </span>beta2 &lt;-<span class="st"> </span><span class="kw">lm</span>(a <span class="op">~</span><span class="st"> </span>x2)<span class="op">$</span>coef[<span class="dv">2</span>]</span></code></pre></div></li>
</ol>
</blockquote>
<div class="sourceCode" id="cb478"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb478-1"><a href="moving-beyond-linearity.html#cb478-1"></a>a &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>beta1<span class="op">*</span>x1</span>
<span id="cb478-2"><a href="moving-beyond-linearity.html#cb478-2"></a>beta2 &lt;-<span class="st"> </span><span class="kw">lm</span>(a <span class="op">~</span><span class="st"> </span>x2)<span class="op">$</span>coef[<span class="dv">2</span>]</span></code></pre></div>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li><p>Keeping <span class="math inline">\(\hat{\beta}_2\)</span> fixed, fit the model
<span class="math display">\[Y - \hat{\beta}_2X_2 = \beta_0 + \beta_1 X_1 + \epsilon.\]</span>
You can do this as follows:</p>
<div class="sourceCode" id="cb479"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb479-1"><a href="moving-beyond-linearity.html#cb479-1"></a><span class="op">&gt;</span><span class="st"> </span>a &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>beta2 <span class="op">*</span><span class="st"> </span>x2</span>
<span id="cb479-2"><a href="moving-beyond-linearity.html#cb479-2"></a><span class="op">&gt;</span><span class="st"> </span>beta1 &lt;-<span class="st"> </span><span class="kw">lm</span>(a <span class="op">~</span><span class="st"> </span>x1)<span class="op">$</span>coef[<span class="dv">2</span>]</span></code></pre></div></li>
</ol>
</blockquote>
<div class="sourceCode" id="cb480"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb480-1"><a href="moving-beyond-linearity.html#cb480-1"></a>a &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>beta2 <span class="op">*</span><span class="st"> </span>x2</span>
<span id="cb480-2"><a href="moving-beyond-linearity.html#cb480-2"></a>beta1 &lt;-<span class="st"> </span><span class="kw">lm</span>(a <span class="op">~</span><span class="st"> </span>x1)<span class="op">$</span>coef[<span class="dv">2</span>]</span></code></pre></div>
<blockquote>
<ol start="5" style="list-style-type: lower-alpha">
<li>Write a for loop to repeat (c) and (d) 1,000 times. Report the estimates of
<span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1,\)</span> and <span class="math inline">\(\hat{\beta}_2\)</span> at each iteration of the
for loop. Create a plot in which each of these values is displayed, with
<span class="math inline">\(\hat{\beta}_0, \hat{\beta}_1,\)</span> and <span class="math inline">\(\hat{\beta}_2\)</span> each shown in a different
color.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb481"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb481-1"><a href="moving-beyond-linearity.html#cb481-1"></a>res &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow =</span> <span class="dv">1000</span>, <span class="dt">ncol =</span> <span class="dv">3</span>)</span>
<span id="cb481-2"><a href="moving-beyond-linearity.html#cb481-2"></a><span class="kw">colnames</span>(res) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;beta2&quot;</span>)</span>
<span id="cb481-3"><a href="moving-beyond-linearity.html#cb481-3"></a>beta1 &lt;-<span class="st"> </span><span class="dv">20</span></span>
<span id="cb481-4"><a href="moving-beyond-linearity.html#cb481-4"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>) {</span>
<span id="cb481-5"><a href="moving-beyond-linearity.html#cb481-5"></a>  beta2 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">-</span><span class="st"> </span>beta1<span class="op">*</span>x1 <span class="op">~</span><span class="st"> </span>x2)<span class="op">$</span>coef[<span class="dv">2</span>]</span>
<span id="cb481-6"><a href="moving-beyond-linearity.html#cb481-6"></a>  beta1 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">-</span><span class="st"> </span>beta2<span class="op">*</span>x2 <span class="op">~</span><span class="st"> </span>x1)<span class="op">$</span>coef[<span class="dv">2</span>]</span>
<span id="cb481-7"><a href="moving-beyond-linearity.html#cb481-7"></a>  beta0 &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">-</span><span class="st"> </span>beta2<span class="op">*</span>x2 <span class="op">~</span><span class="st"> </span>x1)<span class="op">$</span>coef[<span class="dv">1</span>]</span>
<span id="cb481-8"><a href="moving-beyond-linearity.html#cb481-8"></a>  res[i, ] &lt;-<span class="st"> </span><span class="kw">c</span>(beta0, beta1, beta2)</span>
<span id="cb481-9"><a href="moving-beyond-linearity.html#cb481-9"></a>}</span>
<span id="cb481-10"><a href="moving-beyond-linearity.html#cb481-10"></a>res &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(res)</span>
<span id="cb481-11"><a href="moving-beyond-linearity.html#cb481-11"></a>res<span class="op">$</span>Iteration &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">1000</span></span>
<span id="cb481-12"><a href="moving-beyond-linearity.html#cb481-12"></a>res &lt;-<span class="st"> </span><span class="kw">pivot_longer</span>(res, <span class="op">!</span>Iteration)</span>
<span id="cb481-13"><a href="moving-beyond-linearity.html#cb481-13"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(res, <span class="kw">aes</span>(<span class="dt">x=</span>Iteration, <span class="dt">y=</span>value, <span class="dt">color=</span>name)) <span class="op">+</span></span>
<span id="cb481-14"><a href="moving-beyond-linearity.html#cb481-14"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span></span>
<span id="cb481-15"><a href="moving-beyond-linearity.html#cb481-15"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb481-16"><a href="moving-beyond-linearity.html#cb481-16"></a><span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">trans =</span> <span class="st">&quot;log10&quot;</span>)</span>
<span id="cb481-17"><a href="moving-beyond-linearity.html#cb481-17"></a>p</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<blockquote>
<ol start="6" style="list-style-type: lower-alpha">
<li>Compare your answer in (e) to the results of simply performing multiple
linear regression to predict <span class="math inline">\(Y\)</span> using <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. Use the <code>abline()</code>
function to overlay those multiple linear regression coefficient estimates on
the plot obtained in (e).</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb482"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb482-1"><a href="moving-beyond-linearity.html#cb482-1"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2)</span>
<span id="cb482-2"><a href="moving-beyond-linearity.html#cb482-2"></a><span class="kw">coef</span>(fit)</span></code></pre></div>
<pre><code>## (Intercept)          x1          x2 
##  2.00176627  0.05629075  4.08529318</code></pre>
<div class="sourceCode" id="cb484"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb484-1"><a href="moving-beyond-linearity.html#cb484-1"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="kw">coef</span>(fit), <span class="dt">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<blockquote>
<ol start="7" style="list-style-type: lower-alpha">
<li>On this data set, how many backfitting iterations were required in order to
obtain a “good” approximation to the multiple regression coefficient
estimates?</li>
</ol>
</blockquote>
<p>In this case, good estimates were obtained after 3 iterations.</p>
</div>
<div id="question-12-2" class="section level3 hasAnchor">
<h3><span class="header-section-number">7.2.7</span> Question 12<a href="moving-beyond-linearity.html#question-12-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>This problem is a continuation of the previous exercise. In a toy example with
<span class="math inline">\(p = 100\)</span>, show that one can approximate the multiple linear regression
coefficient estimates by repeatedly performing simple linear regression in a
backfitting procedure. How many backfitting iterations are required in order to
obtain a “good” approximation to the multiple regression coefficient estimates?
Create a plot to justify your answer.</p>
</blockquote>
<div class="sourceCode" id="cb485"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb485-1"><a href="moving-beyond-linearity.html#cb485-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb485-2"><a href="moving-beyond-linearity.html#cb485-2"></a></span>
<span id="cb485-3"><a href="moving-beyond-linearity.html#cb485-3"></a>p &lt;-<span class="st"> </span><span class="dv">100</span></span>
<span id="cb485-4"><a href="moving-beyond-linearity.html#cb485-4"></a>n &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb485-5"><a href="moving-beyond-linearity.html#cb485-5"></a></span>
<span id="cb485-6"><a href="moving-beyond-linearity.html#cb485-6"></a>betas &lt;-<span class="st"> </span><span class="kw">rnorm</span>(p) <span class="op">*</span><span class="st"> </span><span class="dv">5</span></span>
<span id="cb485-7"><a href="moving-beyond-linearity.html#cb485-7"></a>x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n <span class="op">*</span><span class="st"> </span>p), <span class="dt">ncol =</span> p, <span class="dt">nrow =</span> n)</span>
<span id="cb485-8"><a href="moving-beyond-linearity.html#cb485-8"></a>y &lt;-<span class="st"> </span>(x <span class="op">%*%</span><span class="st"> </span>betas) <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n)  <span class="co"># ignore beta0 for simplicity</span></span>
<span id="cb485-9"><a href="moving-beyond-linearity.html#cb485-9"></a></span>
<span id="cb485-10"><a href="moving-beyond-linearity.html#cb485-10"></a><span class="co"># multiple regression</span></span>
<span id="cb485-11"><a href="moving-beyond-linearity.html#cb485-11"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb485-12"><a href="moving-beyond-linearity.html#cb485-12"></a><span class="kw">coef</span>(fit)</span></code></pre></div>
<pre><code>##          x1          x2          x3          x4          x5          x6 
##   6.9266184  -2.8428817   1.8686821   3.1466472   1.9601927  -0.5529214 
##          x7          x8          x9         x10         x11         x12 
##   7.4786723  -0.4454637  10.0816005  -0.2391234   6.5832468  11.4451280 
##         x13         x14         x15         x16         x17         x18 
##  -6.9684368  -1.3604495  -0.6310041   3.1786639  -1.4470502 -13.2957027 
##         x19         x20         x21         x22         x23         x24 
## -12.2061834   6.5765842  -1.5227262  -8.8855906  -0.8422954   6.1189230 
##         x25         x26         x27         x28         x29         x30 
##   9.4395267  -2.1697854  -1.2738835  -8.8457987   2.2851699  -3.1922704 
##         x31         x32         x33         x34         x35         x36 
##   2.2812995   3.4695892   5.1162617  -3.0423873   2.4985589  -8.5952764 
##         x37         x38         x39         x40         x41         x42 
##  -3.9539370  -4.2616463 -12.0038342   0.1981058   1.0559250  -1.8205017 
##         x43         x44         x45         x46         x47         x48 
##   3.7739990  -3.6240020  -6.8575534   2.1042998  -4.0228773   7.1880298 
##         x49         x50         x51         x52         x53         x54 
##  -2.1967821   3.3137115   1.6406524  -3.9402065   7.9067705   3.1815846 
##         x55         x56         x57         x58         x59         x60 
##   0.4504175   1.4003479   3.3999814   0.4317695 -14.9255798   1.3816878 
##         x61         x62         x63         x64         x65         x66 
##  -1.8071634   0.9907740   2.9771540   6.9528872  -3.5956916   6.5283946 
##         x67         x68         x69         x70         x71         x72 
##   1.6798820   5.1911857   4.5573256   3.5961319  -5.1909352  -0.4869003 
##         x73         x74         x75         x76         x77         x78 
##   3.1472166  -4.7898363  -2.7402076   2.9247173   3.8659938   2.3686379 
##         x79         x80         x81         x82         x83         x84 
##  -4.4261734  -5.5020688   7.5807239   1.3010702   0.4378713  -0.5856580 
##         x85         x86         x87         x88         x89         x90 
##  -5.9799328   3.0089329  -1.1230969  -0.8857679   4.7211363   4.1042952 
##         x91         x92         x93         x94         x95         x96 
##   6.9492037  -2.3959211   3.2188522   6.9947040  -5.5392641  -4.3114784 
##         x97         x98         x99        x100 
##  -5.7287292  -7.3148812   0.3454408   3.2830658</code></pre>
<div class="sourceCode" id="cb487"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb487-1"><a href="moving-beyond-linearity.html#cb487-1"></a><span class="co"># backfitting</span></span>
<span id="cb487-2"><a href="moving-beyond-linearity.html#cb487-2"></a>backfit &lt;-<span class="st"> </span><span class="cf">function</span>(x, y, <span class="dt">iter =</span> <span class="dv">20</span>) {</span>
<span id="cb487-3"><a href="moving-beyond-linearity.html#cb487-3"></a>  beta &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">ncol =</span> <span class="kw">ncol</span>(x), <span class="dt">nrow =</span> iter <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb487-4"><a href="moving-beyond-linearity.html#cb487-4"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>iter) {</span>
<span id="cb487-5"><a href="moving-beyond-linearity.html#cb487-5"></a>    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(x)) {</span>
<span id="cb487-6"><a href="moving-beyond-linearity.html#cb487-6"></a>      residual &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>(x[, <span class="op">-</span>k] <span class="op">%*%</span><span class="st"> </span>beta[i, <span class="op">-</span>k])</span>
<span id="cb487-7"><a href="moving-beyond-linearity.html#cb487-7"></a>      beta[i <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, k] &lt;-<span class="st"> </span><span class="kw">lm</span>(residual <span class="op">~</span><span class="st"> </span>x[, k])<span class="op">$</span>coef[<span class="dv">2</span>]</span>
<span id="cb487-8"><a href="moving-beyond-linearity.html#cb487-8"></a>    }</span>
<span id="cb487-9"><a href="moving-beyond-linearity.html#cb487-9"></a>  }</span>
<span id="cb487-10"><a href="moving-beyond-linearity.html#cb487-10"></a>  beta[<span class="op">-</span><span class="dv">1</span>, ]</span>
<span id="cb487-11"><a href="moving-beyond-linearity.html#cb487-11"></a>}</span>
<span id="cb487-12"><a href="moving-beyond-linearity.html#cb487-12"></a>res &lt;-<span class="st"> </span><span class="kw">backfit</span>(x, y)</span>
<span id="cb487-13"><a href="moving-beyond-linearity.html#cb487-13"></a>error &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(<span class="kw">sweep</span>(res, <span class="dv">2</span>, betas)<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb487-14"><a href="moving-beyond-linearity.html#cb487-14"></a><span class="kw">plot</span>(error, <span class="dt">log =</span> <span class="st">&quot;x&quot;</span>, <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>)</span></code></pre></div>
<p><img src="07-moving-beyond-linearity_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<div class="sourceCode" id="cb488"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb488-1"><a href="moving-beyond-linearity.html#cb488-1"></a><span class="co"># backfitting error</span></span>
<span id="cb488-2"><a href="moving-beyond-linearity.html#cb488-2"></a>error[<span class="kw">length</span>(error)]</span></code></pre></div>
<pre><code>## [1] 0.001142494</code></pre>
<div class="sourceCode" id="cb490"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb490-1"><a href="moving-beyond-linearity.html#cb490-1"></a><span class="co"># lm error</span></span>
<span id="cb490-2"><a href="moving-beyond-linearity.html#cb490-2"></a><span class="kw">mean</span>((<span class="kw">coef</span>(fit) <span class="op">-</span><span class="st"> </span>betas)<span class="op">^</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.001138655</code></pre>
<p>We need around 5 to 6 iterations to obtain a good estimate of the coefficients.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-model-selection-and-regularization.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tree-based-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": {}
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/danhalligan/ISLRv2-solutions/edit/master/07-moving-beyond-linearity.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
