<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Support Vector Machines | An Introduction to Statistical Learning</title>
  <meta name="description" content="9 Support Vector Machines | An Introduction to Statistical Learning" />
  <meta name="generator" content="bookdown 0.29.3 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Support Vector Machines | An Introduction to Statistical Learning" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Support Vector Machines | An Introduction to Statistical Learning" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tree-based-methods.html"/>
<link rel="next" href="deep-learning.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="islrv2.css" type="text/css" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/aaaakshat/cm-web-fonts@latest/fonts.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ISLRv2 Solutions</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistical-learning.html"><a href="statistical-learning.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a><ul>
<li class="chapter" data-level="2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#conceptual"><i class="fa fa-check"></i><b>2.1</b> Conceptual</a><ul>
<li class="chapter" data-level="2.1.1" data-path="statistical-learning.html"><a href="statistical-learning.html#question-1"><i class="fa fa-check"></i><b>2.1.1</b> Question 1</a></li>
<li class="chapter" data-level="2.1.2" data-path="statistical-learning.html"><a href="statistical-learning.html#question-2"><i class="fa fa-check"></i><b>2.1.2</b> Question 2</a></li>
<li class="chapter" data-level="2.1.3" data-path="statistical-learning.html"><a href="statistical-learning.html#question-3"><i class="fa fa-check"></i><b>2.1.3</b> Question 3</a></li>
<li class="chapter" data-level="2.1.4" data-path="statistical-learning.html"><a href="statistical-learning.html#question-4"><i class="fa fa-check"></i><b>2.1.4</b> Question 4</a></li>
<li class="chapter" data-level="2.1.5" data-path="statistical-learning.html"><a href="statistical-learning.html#question-5"><i class="fa fa-check"></i><b>2.1.5</b> Question 5</a></li>
<li class="chapter" data-level="2.1.6" data-path="statistical-learning.html"><a href="statistical-learning.html#question-6"><i class="fa fa-check"></i><b>2.1.6</b> Question 6</a></li>
<li class="chapter" data-level="2.1.7" data-path="statistical-learning.html"><a href="statistical-learning.html#question-7"><i class="fa fa-check"></i><b>2.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#applied"><i class="fa fa-check"></i><b>2.2</b> Applied</a><ul>
<li class="chapter" data-level="2.2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#question-8"><i class="fa fa-check"></i><b>2.2.1</b> Question 8</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#question-9"><i class="fa fa-check"></i><b>2.2.2</b> Question 9</a></li>
<li class="chapter" data-level="2.2.3" data-path="statistical-learning.html"><a href="statistical-learning.html#question-10"><i class="fa fa-check"></i><b>2.2.3</b> Question 10</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#conceptual-1"><i class="fa fa-check"></i><b>3.1</b> Conceptual</a><ul>
<li class="chapter" data-level="3.1.1" data-path="linear-regression.html"><a href="linear-regression.html#question-1-1"><i class="fa fa-check"></i><b>3.1.1</b> Question 1</a></li>
<li class="chapter" data-level="3.1.2" data-path="linear-regression.html"><a href="linear-regression.html#question-2-1"><i class="fa fa-check"></i><b>3.1.2</b> Question 2</a></li>
<li class="chapter" data-level="3.1.3" data-path="linear-regression.html"><a href="linear-regression.html#question-3-1"><i class="fa fa-check"></i><b>3.1.3</b> Question 3</a></li>
<li class="chapter" data-level="3.1.4" data-path="linear-regression.html"><a href="linear-regression.html#question-4-1"><i class="fa fa-check"></i><b>3.1.4</b> Question 4</a></li>
<li class="chapter" data-level="3.1.5" data-path="linear-regression.html"><a href="linear-regression.html#question-5-1"><i class="fa fa-check"></i><b>3.1.5</b> Question 5</a></li>
<li class="chapter" data-level="3.1.6" data-path="linear-regression.html"><a href="linear-regression.html#question-6-1"><i class="fa fa-check"></i><b>3.1.6</b> Question 6</a></li>
<li class="chapter" data-level="3.1.7" data-path="linear-regression.html"><a href="linear-regression.html#question-7-1"><i class="fa fa-check"></i><b>3.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#applied-1"><i class="fa fa-check"></i><b>3.2</b> Applied</a><ul>
<li class="chapter" data-level="3.2.1" data-path="linear-regression.html"><a href="linear-regression.html#question-8-1"><i class="fa fa-check"></i><b>3.2.1</b> Question 8</a></li>
<li class="chapter" data-level="3.2.2" data-path="linear-regression.html"><a href="linear-regression.html#question-9-1"><i class="fa fa-check"></i><b>3.2.2</b> Question 9</a></li>
<li class="chapter" data-level="3.2.3" data-path="linear-regression.html"><a href="linear-regression.html#question-10-1"><i class="fa fa-check"></i><b>3.2.3</b> Question 10</a></li>
<li class="chapter" data-level="3.2.4" data-path="linear-regression.html"><a href="linear-regression.html#question-11"><i class="fa fa-check"></i><b>3.2.4</b> Question 11</a></li>
<li class="chapter" data-level="3.2.5" data-path="linear-regression.html"><a href="linear-regression.html#question-12"><i class="fa fa-check"></i><b>3.2.5</b> Question 12</a></li>
<li class="chapter" data-level="3.2.6" data-path="linear-regression.html"><a href="linear-regression.html#question-13"><i class="fa fa-check"></i><b>3.2.6</b> Question 13</a></li>
<li class="chapter" data-level="3.2.7" data-path="linear-regression.html"><a href="linear-regression.html#question-14"><i class="fa fa-check"></i><b>3.2.7</b> Question 14</a></li>
<li class="chapter" data-level="3.2.8" data-path="linear-regression.html"><a href="linear-regression.html#question-15"><i class="fa fa-check"></i><b>3.2.8</b> Question 15</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="classification.html"><a href="classification.html"><i class="fa fa-check"></i><b>4</b> Classification</a><ul>
<li class="chapter" data-level="4.1" data-path="classification.html"><a href="classification.html#conceptual-2"><i class="fa fa-check"></i><b>4.1</b> Conceptual</a><ul>
<li class="chapter" data-level="4.1.1" data-path="classification.html"><a href="classification.html#question-1-2"><i class="fa fa-check"></i><b>4.1.1</b> Question 1</a></li>
<li class="chapter" data-level="4.1.2" data-path="classification.html"><a href="classification.html#question-2-2"><i class="fa fa-check"></i><b>4.1.2</b> Question 2</a></li>
<li class="chapter" data-level="4.1.3" data-path="classification.html"><a href="classification.html#question-3-2"><i class="fa fa-check"></i><b>4.1.3</b> Question 3</a></li>
<li class="chapter" data-level="4.1.4" data-path="classification.html"><a href="classification.html#question-4-2"><i class="fa fa-check"></i><b>4.1.4</b> Question 4</a></li>
<li class="chapter" data-level="4.1.5" data-path="classification.html"><a href="classification.html#question-5-2"><i class="fa fa-check"></i><b>4.1.5</b> Question 5</a></li>
<li class="chapter" data-level="4.1.6" data-path="classification.html"><a href="classification.html#question-6-2"><i class="fa fa-check"></i><b>4.1.6</b> Question 6</a></li>
<li class="chapter" data-level="4.1.7" data-path="classification.html"><a href="classification.html#question-7-2"><i class="fa fa-check"></i><b>4.1.7</b> Question 7</a></li>
<li class="chapter" data-level="4.1.8" data-path="classification.html"><a href="classification.html#question-8-2"><i class="fa fa-check"></i><b>4.1.8</b> Question 8</a></li>
<li class="chapter" data-level="4.1.9" data-path="classification.html"><a href="classification.html#question-9-2"><i class="fa fa-check"></i><b>4.1.9</b> Question 9</a></li>
<li class="chapter" data-level="4.1.10" data-path="classification.html"><a href="classification.html#question-10-2"><i class="fa fa-check"></i><b>4.1.10</b> Question 10</a></li>
<li class="chapter" data-level="4.1.11" data-path="classification.html"><a href="classification.html#question-11-1"><i class="fa fa-check"></i><b>4.1.11</b> Question 11</a></li>
<li class="chapter" data-level="4.1.12" data-path="classification.html"><a href="classification.html#question-12-1"><i class="fa fa-check"></i><b>4.1.12</b> Question 12</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="classification.html"><a href="classification.html#applied-2"><i class="fa fa-check"></i><b>4.2</b> Applied</a><ul>
<li class="chapter" data-level="4.2.1" data-path="classification.html"><a href="classification.html#question-13-1"><i class="fa fa-check"></i><b>4.2.1</b> Question 13</a></li>
<li class="chapter" data-level="4.2.2" data-path="classification.html"><a href="classification.html#question-14-1"><i class="fa fa-check"></i><b>4.2.2</b> Question 14</a></li>
<li class="chapter" data-level="4.2.3" data-path="classification.html"><a href="classification.html#question-15-1"><i class="fa fa-check"></i><b>4.2.3</b> Question 15</a></li>
<li class="chapter" data-level="4.2.4" data-path="classification.html"><a href="classification.html#question-13-2"><i class="fa fa-check"></i><b>4.2.4</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resampling-methods.html"><a href="resampling-methods.html"><i class="fa fa-check"></i><b>5</b> Resampling Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="resampling-methods.html"><a href="resampling-methods.html#conceptual-3"><i class="fa fa-check"></i><b>5.1</b> Conceptual</a><ul>
<li class="chapter" data-level="5.1.1" data-path="resampling-methods.html"><a href="resampling-methods.html#question-1-3"><i class="fa fa-check"></i><b>5.1.1</b> Question 1</a></li>
<li class="chapter" data-level="5.1.2" data-path="resampling-methods.html"><a href="resampling-methods.html#question-2-3"><i class="fa fa-check"></i><b>5.1.2</b> Question 2</a></li>
<li class="chapter" data-level="5.1.3" data-path="resampling-methods.html"><a href="resampling-methods.html#question-3-3"><i class="fa fa-check"></i><b>5.1.3</b> Question 3</a></li>
<li class="chapter" data-level="5.1.4" data-path="resampling-methods.html"><a href="resampling-methods.html#question-4-3"><i class="fa fa-check"></i><b>5.1.4</b> Question 4</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="resampling-methods.html"><a href="resampling-methods.html#applied-3"><i class="fa fa-check"></i><b>5.2</b> Applied</a><ul>
<li class="chapter" data-level="5.2.1" data-path="resampling-methods.html"><a href="resampling-methods.html#question-5-3"><i class="fa fa-check"></i><b>5.2.1</b> Question 5</a></li>
<li class="chapter" data-level="5.2.2" data-path="resampling-methods.html"><a href="resampling-methods.html#question-6-3"><i class="fa fa-check"></i><b>5.2.2</b> Question 6</a></li>
<li class="chapter" data-level="5.2.3" data-path="resampling-methods.html"><a href="resampling-methods.html#question-7-3"><i class="fa fa-check"></i><b>5.2.3</b> Question 7</a></li>
<li class="chapter" data-level="5.2.4" data-path="resampling-methods.html"><a href="resampling-methods.html#question-8-3"><i class="fa fa-check"></i><b>5.2.4</b> Question 8</a></li>
<li class="chapter" data-level="5.2.5" data-path="resampling-methods.html"><a href="resampling-methods.html#question-9-3"><i class="fa fa-check"></i><b>5.2.5</b> Question 9</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html"><i class="fa fa-check"></i><b>6</b> Linear Model Selection and Regularization</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#conceptual-4"><i class="fa fa-check"></i><b>6.1</b> Conceptual</a><ul>
<li class="chapter" data-level="6.1.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-1-4"><i class="fa fa-check"></i><b>6.1.1</b> Question 1</a></li>
<li class="chapter" data-level="6.1.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-2-4"><i class="fa fa-check"></i><b>6.1.2</b> Question 2</a></li>
<li class="chapter" data-level="6.1.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-3-4"><i class="fa fa-check"></i><b>6.1.3</b> Question 3</a></li>
<li class="chapter" data-level="6.1.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-4-4"><i class="fa fa-check"></i><b>6.1.4</b> Question 4</a></li>
<li class="chapter" data-level="6.1.5" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-5-4"><i class="fa fa-check"></i><b>6.1.5</b> Question 5</a></li>
<li class="chapter" data-level="6.1.6" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-6-4"><i class="fa fa-check"></i><b>6.1.6</b> Question 6</a></li>
<li class="chapter" data-level="6.1.7" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-7-4"><i class="fa fa-check"></i><b>6.1.7</b> Question 7</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#applied-4"><i class="fa fa-check"></i><b>6.2</b> Applied</a><ul>
<li class="chapter" data-level="6.2.1" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-8-4"><i class="fa fa-check"></i><b>6.2.1</b> Question 8</a></li>
<li class="chapter" data-level="6.2.2" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-9-4"><i class="fa fa-check"></i><b>6.2.2</b> Question 9</a></li>
<li class="chapter" data-level="6.2.3" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-10-3"><i class="fa fa-check"></i><b>6.2.3</b> Question 10</a></li>
<li class="chapter" data-level="6.2.4" data-path="linear-model-selection-and-regularization.html"><a href="linear-model-selection-and-regularization.html#question-11-2"><i class="fa fa-check"></i><b>6.2.4</b> Question 11</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html"><i class="fa fa-check"></i><b>7</b> Moving Beyond Linearity</a><ul>
<li class="chapter" data-level="7.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#conceptual-5"><i class="fa fa-check"></i><b>7.1</b> Conceptual</a><ul>
<li class="chapter" data-level="7.1.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-1-5"><i class="fa fa-check"></i><b>7.1.1</b> Question 1</a></li>
<li class="chapter" data-level="7.1.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-2-5"><i class="fa fa-check"></i><b>7.1.2</b> Question 2</a></li>
<li class="chapter" data-level="7.1.3" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-3-5"><i class="fa fa-check"></i><b>7.1.3</b> Question 3</a></li>
<li class="chapter" data-level="7.1.4" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-4-5"><i class="fa fa-check"></i><b>7.1.4</b> Question 4</a></li>
<li class="chapter" data-level="7.1.5" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-5-5"><i class="fa fa-check"></i><b>7.1.5</b> Question 5</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#applied-5"><i class="fa fa-check"></i><b>7.2</b> Applied</a><ul>
<li class="chapter" data-level="7.2.1" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-6-5"><i class="fa fa-check"></i><b>7.2.1</b> Question 6</a></li>
<li class="chapter" data-level="7.2.2" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-7-5"><i class="fa fa-check"></i><b>7.2.2</b> Question 7</a></li>
<li class="chapter" data-level="7.2.3" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-8-5"><i class="fa fa-check"></i><b>7.2.3</b> Question 8</a></li>
<li class="chapter" data-level="7.2.4" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-9-5"><i class="fa fa-check"></i><b>7.2.4</b> Question 9</a></li>
<li class="chapter" data-level="7.2.5" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-10-4"><i class="fa fa-check"></i><b>7.2.5</b> Question 10</a></li>
<li class="chapter" data-level="7.2.6" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-11-3"><i class="fa fa-check"></i><b>7.2.6</b> Question 11</a></li>
<li class="chapter" data-level="7.2.7" data-path="moving-beyond-linearity.html"><a href="moving-beyond-linearity.html#question-12-2"><i class="fa fa-check"></i><b>7.2.7</b> Question 12</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-methods.html"><a href="tree-based-methods.html"><i class="fa fa-check"></i><b>8</b> Tree-Based Methods</a><ul>
<li class="chapter" data-level="8.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#conceptual-6"><i class="fa fa-check"></i><b>8.1</b> Conceptual</a><ul>
<li class="chapter" data-level="8.1.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-1-6"><i class="fa fa-check"></i><b>8.1.1</b> Question 1</a></li>
<li class="chapter" data-level="8.1.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-2-6"><i class="fa fa-check"></i><b>8.1.2</b> Question 2</a></li>
<li class="chapter" data-level="8.1.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-3-6"><i class="fa fa-check"></i><b>8.1.3</b> Question 3</a></li>
<li class="chapter" data-level="8.1.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-4-6"><i class="fa fa-check"></i><b>8.1.4</b> Question 4</a></li>
<li class="chapter" data-level="8.1.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-5-6"><i class="fa fa-check"></i><b>8.1.5</b> Question 5</a></li>
<li class="chapter" data-level="8.1.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-6-6"><i class="fa fa-check"></i><b>8.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#applied-6"><i class="fa fa-check"></i><b>8.2</b> Applied</a><ul>
<li class="chapter" data-level="8.2.1" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-7-6"><i class="fa fa-check"></i><b>8.2.1</b> Question 7</a></li>
<li class="chapter" data-level="8.2.2" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-8-6"><i class="fa fa-check"></i><b>8.2.2</b> Question 8</a></li>
<li class="chapter" data-level="8.2.3" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-9-6"><i class="fa fa-check"></i><b>8.2.3</b> Question 9</a></li>
<li class="chapter" data-level="8.2.4" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-10-5"><i class="fa fa-check"></i><b>8.2.4</b> Question 10</a></li>
<li class="chapter" data-level="8.2.5" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-11-4"><i class="fa fa-check"></i><b>8.2.5</b> Question 11</a></li>
<li class="chapter" data-level="8.2.6" data-path="tree-based-methods.html"><a href="tree-based-methods.html#question-12-3"><i class="fa fa-check"></i><b>8.2.6</b> Question 12</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>9</b> Support Vector Machines</a><ul>
<li class="chapter" data-level="9.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#conceptual-7"><i class="fa fa-check"></i><b>9.1</b> Conceptual</a><ul>
<li class="chapter" data-level="9.1.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-1-7"><i class="fa fa-check"></i><b>9.1.1</b> Question 1</a></li>
<li class="chapter" data-level="9.1.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-2-7"><i class="fa fa-check"></i><b>9.1.2</b> Question 2</a></li>
<li class="chapter" data-level="9.1.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-3-7"><i class="fa fa-check"></i><b>9.1.3</b> Question 3</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#applied-7"><i class="fa fa-check"></i><b>9.2</b> Applied</a><ul>
<li class="chapter" data-level="9.2.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-4-7"><i class="fa fa-check"></i><b>9.2.1</b> Question 4</a></li>
<li class="chapter" data-level="9.2.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-5-7"><i class="fa fa-check"></i><b>9.2.2</b> Question 5</a></li>
<li class="chapter" data-level="9.2.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-6-7"><i class="fa fa-check"></i><b>9.2.3</b> Question 6</a></li>
<li class="chapter" data-level="9.2.4" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-7-7"><i class="fa fa-check"></i><b>9.2.4</b> Question 7</a></li>
<li class="chapter" data-level="9.2.5" data-path="support-vector-machines.html"><a href="support-vector-machines.html#question-8-7"><i class="fa fa-check"></i><b>9.2.5</b> Question 8</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>10</b> Deep Learning</a><ul>
<li class="chapter" data-level="10.1" data-path="deep-learning.html"><a href="deep-learning.html#conceptual-8"><i class="fa fa-check"></i><b>10.1</b> Conceptual</a><ul>
<li class="chapter" data-level="10.1.1" data-path="deep-learning.html"><a href="deep-learning.html#question-1-8"><i class="fa fa-check"></i><b>10.1.1</b> Question 1</a></li>
<li class="chapter" data-level="10.1.2" data-path="deep-learning.html"><a href="deep-learning.html#question-2-8"><i class="fa fa-check"></i><b>10.1.2</b> Question 2</a></li>
<li class="chapter" data-level="10.1.3" data-path="deep-learning.html"><a href="deep-learning.html#question-3-8"><i class="fa fa-check"></i><b>10.1.3</b> Question 3</a></li>
<li class="chapter" data-level="10.1.4" data-path="deep-learning.html"><a href="deep-learning.html#question-4-8"><i class="fa fa-check"></i><b>10.1.4</b> Question 4</a></li>
<li class="chapter" data-level="10.1.5" data-path="deep-learning.html"><a href="deep-learning.html#question-5-8"><i class="fa fa-check"></i><b>10.1.5</b> Question 5</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="deep-learning.html"><a href="deep-learning.html#applied-8"><i class="fa fa-check"></i><b>10.2</b> Applied</a><ul>
<li class="chapter" data-level="10.2.1" data-path="deep-learning.html"><a href="deep-learning.html#question-6-8"><i class="fa fa-check"></i><b>10.2.1</b> Question 6</a></li>
<li class="chapter" data-level="10.2.2" data-path="deep-learning.html"><a href="deep-learning.html#question-7-8"><i class="fa fa-check"></i><b>10.2.2</b> Question 7</a></li>
<li class="chapter" data-level="10.2.3" data-path="deep-learning.html"><a href="deep-learning.html#question-8-8"><i class="fa fa-check"></i><b>10.2.3</b> Question 8</a></li>
<li class="chapter" data-level="10.2.4" data-path="deep-learning.html"><a href="deep-learning.html#question-9-7"><i class="fa fa-check"></i><b>10.2.4</b> Question 9</a></li>
<li class="chapter" data-level="10.2.5" data-path="deep-learning.html"><a href="deep-learning.html#question-10-6"><i class="fa fa-check"></i><b>10.2.5</b> Question 10</a></li>
<li class="chapter" data-level="10.2.6" data-path="deep-learning.html"><a href="deep-learning.html#question-11-5"><i class="fa fa-check"></i><b>10.2.6</b> Question 11</a></li>
<li class="chapter" data-level="10.2.7" data-path="deep-learning.html"><a href="deep-learning.html#question-12-4"><i class="fa fa-check"></i><b>10.2.7</b> Question 12</a></li>
<li class="chapter" data-level="10.2.8" data-path="deep-learning.html"><a href="deep-learning.html#question-13-3"><i class="fa fa-check"></i><b>10.2.8</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html"><i class="fa fa-check"></i><b>11</b> Survival Analysis and Censored Data</a><ul>
<li class="chapter" data-level="11.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#conceptual-9"><i class="fa fa-check"></i><b>11.1</b> Conceptual</a><ul>
<li class="chapter" data-level="11.1.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-1-9"><i class="fa fa-check"></i><b>11.1.1</b> Question 1</a></li>
<li class="chapter" data-level="11.1.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-2-9"><i class="fa fa-check"></i><b>11.1.2</b> Question 2</a></li>
<li class="chapter" data-level="11.1.3" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-3-9"><i class="fa fa-check"></i><b>11.1.3</b> Question 3</a></li>
<li class="chapter" data-level="11.1.4" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-4-9"><i class="fa fa-check"></i><b>11.1.4</b> Question 4</a></li>
<li class="chapter" data-level="11.1.5" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-5-9"><i class="fa fa-check"></i><b>11.1.5</b> Question 5</a></li>
<li class="chapter" data-level="11.1.6" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-6-9"><i class="fa fa-check"></i><b>11.1.6</b> Question 6</a></li>
<li class="chapter" data-level="11.1.7" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-7-9"><i class="fa fa-check"></i><b>11.1.7</b> Question 7</a></li>
<li class="chapter" data-level="11.1.8" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-8-9"><i class="fa fa-check"></i><b>11.1.8</b> Question 8</a></li>
<li class="chapter" data-level="11.1.9" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-9-8"><i class="fa fa-check"></i><b>11.1.9</b> Question 9</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#applied-9"><i class="fa fa-check"></i><b>11.2</b> Applied</a><ul>
<li class="chapter" data-level="11.2.1" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-10-7"><i class="fa fa-check"></i><b>11.2.1</b> Question 10</a></li>
<li class="chapter" data-level="11.2.2" data-path="survival-analysis-and-censored-data.html"><a href="survival-analysis-and-censored-data.html#question-11-6"><i class="fa fa-check"></i><b>11.2.2</b> Question 11</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html"><i class="fa fa-check"></i><b>12</b> Unsupervised Learning</a><ul>
<li class="chapter" data-level="12.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#conceptual-10"><i class="fa fa-check"></i><b>12.1</b> Conceptual</a><ul>
<li class="chapter" data-level="12.1.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-1-10"><i class="fa fa-check"></i><b>12.1.1</b> Question 1</a></li>
<li class="chapter" data-level="12.1.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-2-10"><i class="fa fa-check"></i><b>12.1.2</b> Question 2</a></li>
<li class="chapter" data-level="12.1.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-3-10"><i class="fa fa-check"></i><b>12.1.3</b> Question 3</a></li>
<li class="chapter" data-level="12.1.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-4-10"><i class="fa fa-check"></i><b>12.1.4</b> Question 4</a></li>
<li class="chapter" data-level="12.1.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-5-10"><i class="fa fa-check"></i><b>12.1.5</b> Question 5</a></li>
<li class="chapter" data-level="12.1.6" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-6-10"><i class="fa fa-check"></i><b>12.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#applied-10"><i class="fa fa-check"></i><b>12.2</b> Applied</a><ul>
<li class="chapter" data-level="12.2.1" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-7-10"><i class="fa fa-check"></i><b>12.2.1</b> Question 7</a></li>
<li class="chapter" data-level="12.2.2" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-8-10"><i class="fa fa-check"></i><b>12.2.2</b> Question 8</a></li>
<li class="chapter" data-level="12.2.3" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-9-9"><i class="fa fa-check"></i><b>12.2.3</b> Question 9</a></li>
<li class="chapter" data-level="12.2.4" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-10-8"><i class="fa fa-check"></i><b>12.2.4</b> Question 10</a></li>
<li class="chapter" data-level="12.2.5" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-11-7"><i class="fa fa-check"></i><b>12.2.5</b> Question 11</a></li>
<li class="chapter" data-level="12.2.6" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-12-5"><i class="fa fa-check"></i><b>12.2.6</b> Question 12</a></li>
<li class="chapter" data-level="12.2.7" data-path="unsupervised-learning.html"><a href="unsupervised-learning.html#question-13-4"><i class="fa fa-check"></i><b>12.2.7</b> Question 13</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-testing.html"><a href="multiple-testing.html"><i class="fa fa-check"></i><b>13</b> Multiple Testing</a><ul>
<li class="chapter" data-level="13.1" data-path="multiple-testing.html"><a href="multiple-testing.html#conceptual-11"><i class="fa fa-check"></i><b>13.1</b> Conceptual</a><ul>
<li class="chapter" data-level="13.1.1" data-path="multiple-testing.html"><a href="multiple-testing.html#question-1-11"><i class="fa fa-check"></i><b>13.1.1</b> Question 1</a></li>
<li class="chapter" data-level="13.1.2" data-path="multiple-testing.html"><a href="multiple-testing.html#question-2-11"><i class="fa fa-check"></i><b>13.1.2</b> Question 2</a></li>
<li class="chapter" data-level="13.1.3" data-path="multiple-testing.html"><a href="multiple-testing.html#question-3-11"><i class="fa fa-check"></i><b>13.1.3</b> Question 3</a></li>
<li class="chapter" data-level="13.1.4" data-path="multiple-testing.html"><a href="multiple-testing.html#question-4-11"><i class="fa fa-check"></i><b>13.1.4</b> Question 4</a></li>
<li class="chapter" data-level="13.1.5" data-path="multiple-testing.html"><a href="multiple-testing.html#question-5-11"><i class="fa fa-check"></i><b>13.1.5</b> Question 5</a></li>
<li class="chapter" data-level="13.1.6" data-path="multiple-testing.html"><a href="multiple-testing.html#question-6-11"><i class="fa fa-check"></i><b>13.1.6</b> Question 6</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="multiple-testing.html"><a href="multiple-testing.html#applied-11"><i class="fa fa-check"></i><b>13.2</b> Applied</a><ul>
<li class="chapter" data-level="13.2.1" data-path="multiple-testing.html"><a href="multiple-testing.html#question-7-11"><i class="fa fa-check"></i><b>13.2.1</b> Question 7</a></li>
<li class="chapter" data-level="13.2.2" data-path="multiple-testing.html"><a href="multiple-testing.html#question-8-11"><i class="fa fa-check"></i><b>13.2.2</b> Question 8</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="support-vector-machines" class="section level1 hasAnchor">
<h1><span class="header-section-number">9</span> Support Vector Machines<a href="support-vector-machines.html#support-vector-machines" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="conceptual-7" class="section level2 hasAnchor">
<h2><span class="header-section-number">9.1</span> Conceptual<a href="support-vector-machines.html#conceptual-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="question-1-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.1.1</span> Question 1<a href="support-vector-machines.html#question-1-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>This problem involves hyperplanes in two dimensions.</p>
<ol style="list-style-type: lower-alpha">
<li>Sketch the hyperplane <span class="math inline">\(1 + 3X_1 − X_2 = 0\)</span>. Indicate the set of points for
which <span class="math inline">\(1 + 3X_1 − X_2 &gt; 0\)</span>, as well as the set of points for which
<span class="math inline">\(1 + 3X_1 − X_2 &lt; 0\)</span>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb607"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb607-1"><a href="support-vector-machines.html#cb607-1"></a><span class="kw">library</span>(ggplot2)</span>
<span id="cb607-2"><a href="support-vector-machines.html#cb607-2"></a>xlim &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb607-3"><a href="support-vector-machines.html#cb607-3"></a>ylim &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">30</span>, <span class="dv">30</span>)</span>
<span id="cb607-4"><a href="support-vector-machines.html#cb607-4"></a>points &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(</span>
<span id="cb607-5"><a href="support-vector-machines.html#cb607-5"></a>  <span class="dt">X1 =</span> <span class="kw">seq</span>(xlim[<span class="dv">1</span>], xlim[<span class="dv">2</span>], <span class="dt">length.out =</span> <span class="dv">50</span>), </span>
<span id="cb607-6"><a href="support-vector-machines.html#cb607-6"></a>  <span class="dt">X2 =</span> <span class="kw">seq</span>(ylim[<span class="dv">1</span>], ylim[<span class="dv">2</span>], <span class="dt">length.out =</span> <span class="dv">50</span>)</span>
<span id="cb607-7"><a href="support-vector-machines.html#cb607-7"></a>)</span>
<span id="cb607-8"><a href="support-vector-machines.html#cb607-8"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(points, <span class="kw">aes</span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> X2)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb607-9"><a href="support-vector-machines.html#cb607-9"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">1</span>, <span class="dt">slope =</span> <span class="dv">3</span>) <span class="op">+</span><span class="st">  </span><span class="co"># X2 = 1 + 3X1 </span></span>
<span id="cb607-10"><a href="support-vector-machines.html#cb607-10"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span>
<span id="cb607-11"><a href="support-vector-machines.html#cb607-11"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> <span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span>X1 <span class="op">-</span><span class="st"> </span>X2 <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>), <span class="dt">size =</span> <span class="fl">0.1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb607-12"><a href="support-vector-machines.html#cb607-12"></a><span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">name =</span> <span class="st">&quot;1 + 3X1 − X2 &gt; 0&quot;</span>)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>On the same plot, sketch the hyperplane <span class="math inline">\(−2 + X_1 + 2X_2 = 0\)</span>. Indicate the
set of points for which <span class="math inline">\(−2 + X_1 + 2X_2 &gt; 0\)</span>, as well as the set of points
for which <span class="math inline">\(−2 + X_1 + 2X_2 &lt; 0\)</span>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb608"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb608-1"><a href="support-vector-machines.html#cb608-1"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">1</span>, <span class="dt">slope =</span> <span class="dv">-1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">+</span><span class="st">  </span><span class="co"># X2 = 1 - X1/2</span></span>
<span id="cb608-2"><a href="support-vector-machines.html#cb608-2"></a><span class="st">  </span><span class="kw">geom_point</span>(</span>
<span id="cb608-3"><a href="support-vector-machines.html#cb608-3"></a>    <span class="kw">aes</span>(<span class="dt">color =</span> <span class="kw">interaction</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="dv">3</span><span class="op">*</span>X1 <span class="op">-</span><span class="st"> </span>X2 <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, <span class="dv">-2</span> <span class="op">+</span><span class="st"> </span>X1 <span class="op">+</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>X2 <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)), </span>
<span id="cb608-4"><a href="support-vector-machines.html#cb608-4"></a>    <span class="dt">size =</span> <span class="fl">0.5</span></span>
<span id="cb608-5"><a href="support-vector-machines.html#cb608-5"></a>  ) <span class="op">+</span><span class="st"> </span></span>
<span id="cb608-6"><a href="support-vector-machines.html#cb608-6"></a><span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">name =</span> <span class="st">&quot;(1 + 3X1 − X2 &gt; 0).(−2 + X1 + 2X2 &gt; 0)&quot;</span>)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="question-2-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.1.2</span> Question 2<a href="support-vector-machines.html#question-2-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>We have seen that in <span class="math inline">\(p = 2\)</span> dimensions, a linear decision boundary takes the
form <span class="math inline">\(\beta_0 + \beta_1X_1 + \beta_2X_2 = 0\)</span>. We now investigate a non-linear
decision boundary.</p>
<ol style="list-style-type: lower-alpha">
<li>Sketch the curve <span class="math display">\[(1+X_1)^2 +(2−X_2)^2 = 4\]</span>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb609-1"><a href="support-vector-machines.html#cb609-1"></a>points &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(</span>
<span id="cb609-2"><a href="support-vector-machines.html#cb609-2"></a>  <span class="dt">X1 =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">2</span>, <span class="dt">length.out =</span> <span class="dv">100</span>), </span>
<span id="cb609-3"><a href="support-vector-machines.html#cb609-3"></a>  <span class="dt">X2 =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb609-4"><a href="support-vector-machines.html#cb609-4"></a>)</span>
<span id="cb609-5"><a href="support-vector-machines.html#cb609-5"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(points, <span class="kw">aes</span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> X2, <span class="dt">z =</span> (<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>X1)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">-</span><span class="st"> </span>X2)<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">4</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb609-6"><a href="support-vector-machines.html#cb609-6"></a><span class="st">  </span><span class="kw">geom_contour</span>(<span class="dt">breaks =</span> <span class="dv">0</span>, <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb609-7"><a href="support-vector-machines.html#cb609-7"></a><span class="st">  </span><span class="kw">theme_bw</span>()</span>
<span id="cb609-8"><a href="support-vector-machines.html#cb609-8"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>On your sketch, indicate the set of points for which
<span class="math display">\[(1 + X_1)^2 + (2 − X_2)^2 &gt; 4,\]</span> as well as the set of points for which
<span class="math display">\[(1 + X_1)^2 + (2 − X_2)^2 \leq 4.\]</span></li>
</ol>
</blockquote>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="support-vector-machines.html#cb610-1"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">color =</span> (<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>X1)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">-</span><span class="st"> </span>X2)<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">4</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>), <span class="dt">size =</span> <span class="fl">0.1</span>)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Suppose that a classifier assigns an observation to the blue class if <span class="math display">\[(1
+ X_1)^2 + (2 − X_2)^2 &gt; 4,\]</span> and to the red class otherwise. To what class
is the observation <span class="math inline">\((0, 0)\)</span> classified? <span class="math inline">\((−1, 1)\)</span>? <span class="math inline">\((2, 2)\)</span>? <span class="math inline">\((3, 8)\)</span>?</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb611"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb611-1"><a href="support-vector-machines.html#cb611-1"></a>points &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb611-2"><a href="support-vector-machines.html#cb611-2"></a>  <span class="dt">X1 =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">-1</span>, <span class="dv">2</span>, <span class="dv">3</span>),</span>
<span id="cb611-3"><a href="support-vector-machines.html#cb611-3"></a>  <span class="dt">X2 =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">8</span>)</span>
<span id="cb611-4"><a href="support-vector-machines.html#cb611-4"></a>)</span>
<span id="cb611-5"><a href="support-vector-machines.html#cb611-5"></a><span class="kw">ifelse</span>((<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>points<span class="op">$</span>X1)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">-</span><span class="st"> </span>points<span class="op">$</span>X2)<span class="op">^</span><span class="dv">2</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">4</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;blue&quot; &quot;red&quot;  &quot;blue&quot; &quot;blue&quot;</code></pre>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>Argue that while the decision boundary in (c) is not linear in terms of
<span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, it is linear in terms of <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_1^2\)</span>, <span class="math inline">\(X_2\)</span>, and
<span class="math inline">\(X_2^2\)</span>.</li>
</ol>
</blockquote>
<p>The decision boundary is <span class="math display">\[(1 + X_1)^2 + (2 − X_2)^2 -4 = 0\]</span> which we can expand
to:
<span class="math display">\[1 + 2X_1 + X_1^2 + 4 − 4X_2 + X_2^2 - 4 = 0\]</span>
which is linear in terms of <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_1^2\)</span>, <span class="math inline">\(X_2\)</span>, <span class="math inline">\(X_2^2\)</span>.</p>
</div>
<div id="question-3-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.1.3</span> Question 3<a href="support-vector-machines.html#question-3-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Here we explore the maximal margin classifier on a toy data set.</p>
<ol style="list-style-type: lower-alpha">
<li><p>We are given <span class="math inline">\(n = 7\)</span> observations in <span class="math inline">\(p = 2\)</span> dimensions. For each
observation, there is an associated class label.</p>
<table>
<thead>
<tr class="header">
<th>Obs.</th>
<th><span class="math inline">\(X_1\)</span></th>
<th><span class="math inline">\(X_2\)</span></th>
<th><span class="math inline">\(Y\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>3</td>
<td>4</td>
<td>Red</td>
</tr>
<tr class="even">
<td>2</td>
<td>2</td>
<td>2</td>
<td>Red</td>
</tr>
<tr class="odd">
<td>3</td>
<td>4</td>
<td>4</td>
<td>Red</td>
</tr>
<tr class="even">
<td>4</td>
<td>1</td>
<td>4</td>
<td>Red</td>
</tr>
<tr class="odd">
<td>5</td>
<td>2</td>
<td>1</td>
<td>Blue</td>
</tr>
<tr class="even">
<td>6</td>
<td>4</td>
<td>3</td>
<td>Blue</td>
</tr>
<tr class="odd">
<td>7</td>
<td>4</td>
<td>1</td>
<td>Blue</td>
</tr>
</tbody>
</table>
<p>Sketch the observations.</p></li>
</ol>
</blockquote>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb613-1"><a href="support-vector-machines.html#cb613-1"></a>data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb613-2"><a href="support-vector-machines.html#cb613-2"></a>  <span class="dt">X1 =</span> <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">4</span>),</span>
<span id="cb613-3"><a href="support-vector-machines.html#cb613-3"></a>  <span class="dt">X2 =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>),</span>
<span id="cb613-4"><a href="support-vector-machines.html#cb613-4"></a>  <span class="dt">Y  =</span> <span class="kw">c</span>(<span class="kw">rep</span>(<span class="st">&quot;Red&quot;</span>, <span class="dv">4</span>), <span class="kw">rep</span>(<span class="st">&quot;Blue&quot;</span>, <span class="dv">3</span>))</span>
<span id="cb613-5"><a href="support-vector-machines.html#cb613-5"></a>)</span>
<span id="cb613-6"><a href="support-vector-machines.html#cb613-6"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x =</span> X1, <span class="dt">y =</span> X2, <span class="dt">color =</span> Y)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb613-7"><a href="support-vector-machines.html#cb613-7"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb613-8"><a href="support-vector-machines.html#cb613-8"></a><span class="st">  </span><span class="kw">scale_colour_identity</span>() <span class="op">+</span></span>
<span id="cb613-9"><a href="support-vector-machines.html#cb613-9"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">4.5</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">4.5</span>))</span>
<span id="cb613-10"><a href="support-vector-machines.html#cb613-10"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Sketch the optimal separating hyperplane, and provide the equation for this
hyperplane (of the form (9.1)).</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="support-vector-machines.html#cb614-1"></a><span class="kw">library</span>(e1071)</span>
<span id="cb614-2"><a href="support-vector-machines.html#cb614-2"></a></span>
<span id="cb614-3"><a href="support-vector-machines.html#cb614-3"></a>fit &lt;-<span class="st"> </span><span class="kw">svm</span>(<span class="kw">as.factor</span>(Y) <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data, <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>, <span class="dt">cost =</span> <span class="dv">10</span>, <span class="dt">scale =</span> <span class="ot">FALSE</span>)</span>
<span id="cb614-4"><a href="support-vector-machines.html#cb614-4"></a></span>
<span id="cb614-5"><a href="support-vector-machines.html#cb614-5"></a><span class="co"># Extract beta_0, beta_1, beta_2</span></span>
<span id="cb614-6"><a href="support-vector-machines.html#cb614-6"></a>beta &lt;-<span class="st"> </span><span class="kw">c</span>(</span>
<span id="cb614-7"><a href="support-vector-machines.html#cb614-7"></a>  <span class="op">-</span>fit<span class="op">$</span>rho,</span>
<span id="cb614-8"><a href="support-vector-machines.html#cb614-8"></a>  <span class="kw">drop</span>(<span class="kw">t</span>(fit<span class="op">$</span>coefs) <span class="op">%*%</span><span class="st"> </span><span class="kw">as.matrix</span>(data[fit<span class="op">$</span>index, <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]))</span>
<span id="cb614-9"><a href="support-vector-machines.html#cb614-9"></a>)</span>
<span id="cb614-10"><a href="support-vector-machines.html#cb614-10"></a><span class="kw">names</span>(beta) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;B0&quot;</span>, <span class="st">&quot;B1&quot;</span>, <span class="st">&quot;B2&quot;</span>)</span>
<span id="cb614-11"><a href="support-vector-machines.html#cb614-11"></a>p &lt;-<span class="st"> </span>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="op">-</span>beta[<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span>beta[<span class="dv">3</span>], <span class="dt">slope =</span> <span class="op">-</span>beta[<span class="dv">2</span>] <span class="op">/</span><span class="st"> </span>beta[<span class="dv">3</span>], <span class="dt">lty =</span> <span class="dv">2</span>)</span>
<span id="cb614-12"><a href="support-vector-machines.html#cb614-12"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Describe the classification rule for the maximal margin classifier. It
should be something along the lines of “Classify to Red if <span class="math inline">\(\beta_0 + \beta_1X_1 + \beta_2X_2 &gt; 0\)</span>, and classify to Blue otherwise.” Provide the
values for <span class="math inline">\(\beta_0, \beta_1,\)</span> and <span class="math inline">\(\beta_2\)</span>.</li>
</ol>
</blockquote>
<p>Classify to red if <span class="math inline">\(\beta_0 + \beta_1X_1 + \beta_2X_2 &gt; 0\)</span> and blue otherwise
where <span class="math inline">\(\beta_0 = 1\)</span>, <span class="math inline">\(\beta_1 = -2\)</span>,
<span class="math inline">\(\beta_2 = 2\)</span>.</p>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>On your sketch, indicate the margin for the maximal margin hyperplane.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb615"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb615-1"><a href="support-vector-machines.html#cb615-1"></a>p &lt;-<span class="st"> </span>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_ribbon</span>(</span>
<span id="cb615-2"><a href="support-vector-machines.html#cb615-2"></a>  <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">ymin =</span> ymin, <span class="dt">ymax =</span> ymax),</span>
<span id="cb615-3"><a href="support-vector-machines.html#cb615-3"></a>  <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">5</span>), <span class="dt">ymin =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span>), <span class="dt">ymax =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">5</span>)),</span>
<span id="cb615-4"><a href="support-vector-machines.html#cb615-4"></a>  <span class="dt">alpha =</span> <span class="fl">0.1</span>, <span class="dt">fill =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb615-5"><a href="support-vector-machines.html#cb615-5"></a>  <span class="dt">inherit.aes =</span> <span class="ot">FALSE</span></span>
<span id="cb615-6"><a href="support-vector-machines.html#cb615-6"></a>)</span>
<span id="cb615-7"><a href="support-vector-machines.html#cb615-7"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<blockquote>
<ol start="5" style="list-style-type: lower-alpha">
<li>Indicate the support vectors for the maximal margin classifier.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="support-vector-machines.html#cb616-1"></a>p &lt;-<span class="st"> </span>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data =</span> data[fit<span class="op">$</span>index, ], <span class="dt">size =</span> <span class="dv">4</span>)</span>
<span id="cb616-2"><a href="support-vector-machines.html#cb616-2"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>The support vectors (from the svm fit object) are shown above. Arguably,
there’s another support vector, since four points exactly touch the margin.</p>
<blockquote>
<ol start="6" style="list-style-type: lower-alpha">
<li>Argue that a slight movement of the seventh observation would not affect
the maximal margin hyperplane.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb617-1"><a href="support-vector-machines.html#cb617-1"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data =</span> data[<span class="dv">7</span>, , <span class="dt">drop =</span> <span class="ot">FALSE</span>], <span class="dt">size =</span> <span class="dv">4</span>, <span class="dt">color =</span> <span class="st">&quot;purple&quot;</span>)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>The 7th point is shown in purple above. It is not a support vector, and not
close to the margin, so small changes in its X1, X2 values would not affect the
current calculated margin.</p>
<blockquote>
<ol start="7" style="list-style-type: lower-alpha">
<li>Sketch a hyperplane that is <em>not</em> the optimal separating hyperplane, and
provide the equation for this hyperplane.</li>
</ol>
</blockquote>
<p>A non-optimal hyperline that still separates the blue and red points would
be one that touches the (red) point at X1 = 2, X2 = 2 and the (blue) point at
X1 = 4, X2 = 3. This gives line <span class="math inline">\(y = x/2 + 1\)</span> or, when <span class="math inline">\(\beta_0 = -1\)</span>,
<span class="math inline">\(\beta_1 = -1/2\)</span>, <span class="math inline">\(\beta_2 = 1\)</span>.</p>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="support-vector-machines.html#cb618-1"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">1</span>, <span class="dt">slope =</span> <span class="fl">0.5</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<blockquote>
<ol start="8" style="list-style-type: lower-alpha">
<li>Draw an additional observation on the plot so that the two classes are no
longer separable by a hyperplane.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb619"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb619-1"><a href="support-vector-machines.html#cb619-1"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">X1 =</span> <span class="dv">1</span>, <span class="dt">X2 =</span> <span class="dv">3</span>, <span class="dt">Y  =</span> <span class="st">&quot;Blue&quot;</span>), <span class="dt">shape =</span> <span class="dv">15</span>, <span class="dt">size =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
</div>
<div id="applied-7" class="section level2 hasAnchor">
<h2><span class="header-section-number">9.2</span> Applied<a href="support-vector-machines.html#applied-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="question-4-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.2.1</span> Question 4<a href="support-vector-machines.html#question-4-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>Generate a simulated two-class data set with 100 observations and two features
in which there is a visible but non-linear separation between the two classes.
Show that in this setting, a support vector machine with a polynomial kernel
(with degree greater than 1) or a radial kernel will outperform a support
vector classifier on the training data. Which technique performs best on the
test data? Make plots and report training and test error rates in order to
back up your assertions.</p>
</blockquote>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="support-vector-machines.html#cb620-1"></a><span class="kw">set.seed</span>(<span class="dv">10</span>)</span>
<span id="cb620-2"><a href="support-vector-machines.html#cb620-2"></a>data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb620-3"><a href="support-vector-machines.html#cb620-3"></a>  <span class="dt">x =</span> <span class="kw">runif</span>(<span class="dv">100</span>),</span>
<span id="cb620-4"><a href="support-vector-machines.html#cb620-4"></a>  <span class="dt">y =</span> <span class="kw">runif</span>(<span class="dv">100</span>)</span>
<span id="cb620-5"><a href="support-vector-machines.html#cb620-5"></a>)</span>
<span id="cb620-6"><a href="support-vector-machines.html#cb620-6"></a>score &lt;-<span class="st"> </span>(<span class="dv">2</span><span class="op">*</span>data<span class="op">$</span>x<span class="fl">-0.5</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span>(data<span class="op">$</span>y)<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb620-7"><a href="support-vector-machines.html#cb620-7"></a>data<span class="op">$</span>class &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">ifelse</span>(score <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>))</span>
<span id="cb620-8"><a href="support-vector-machines.html#cb620-8"></a></span>
<span id="cb620-9"><a href="support-vector-machines.html#cb620-9"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">color =</span> class)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb620-10"><a href="support-vector-machines.html#cb620-10"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">scale_colour_identity</span>()</span>
<span id="cb620-11"><a href="support-vector-machines.html#cb620-11"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<div class="sourceCode" id="cb621"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb621-1"><a href="support-vector-machines.html#cb621-1"></a>train &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">50</span></span>
<span id="cb621-2"><a href="support-vector-machines.html#cb621-2"></a>test &lt;-<span class="st"> </span><span class="dv">51</span><span class="op">:</span><span class="dv">100</span></span>
<span id="cb621-3"><a href="support-vector-machines.html#cb621-3"></a></span>
<span id="cb621-4"><a href="support-vector-machines.html#cb621-4"></a>fits &lt;-<span class="st"> </span><span class="kw">list</span>(</span>
<span id="cb621-5"><a href="support-vector-machines.html#cb621-5"></a>  <span class="st">&quot;Radial&quot;</span> =<span class="st"> </span><span class="kw">svm</span>(class <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data[train, ], <span class="dt">kernel =</span> <span class="st">&quot;radial&quot;</span>),</span>
<span id="cb621-6"><a href="support-vector-machines.html#cb621-6"></a>  <span class="st">&quot;Polynomial&quot;</span> =<span class="st"> </span><span class="kw">svm</span>(class <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data[train, ], <span class="dt">kernel =</span> <span class="st">&quot;polynomial&quot;</span>, <span class="dt">degree =</span> <span class="dv">2</span>),</span>
<span id="cb621-7"><a href="support-vector-machines.html#cb621-7"></a>  <span class="st">&quot;Linear&quot;</span> =<span class="st"> </span><span class="kw">svm</span>(class <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data[train, ], <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb621-8"><a href="support-vector-machines.html#cb621-8"></a>)</span>
<span id="cb621-9"><a href="support-vector-machines.html#cb621-9"></a></span>
<span id="cb621-10"><a href="support-vector-machines.html#cb621-10"></a>err &lt;-<span class="st"> </span><span class="cf">function</span>(model, data) {</span>
<span id="cb621-11"><a href="support-vector-machines.html#cb621-11"></a>  out &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">predict</span>(model, data), data<span class="op">$</span>class)</span>
<span id="cb621-12"><a href="support-vector-machines.html#cb621-12"></a>  (out[<span class="dv">1</span>, <span class="dv">2</span>] <span class="op">+</span><span class="st"> </span>out[<span class="dv">2</span>, <span class="dv">1</span>]) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(out)</span>
<span id="cb621-13"><a href="support-vector-machines.html#cb621-13"></a>}</span>
<span id="cb621-14"><a href="support-vector-machines.html#cb621-14"></a><span class="kw">plot</span>(fits[[<span class="dv">1</span>]], data)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb622-1"><a href="support-vector-machines.html#cb622-1"></a><span class="kw">plot</span>(fits[[<span class="dv">2</span>]], data)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-13-3.png" width="672" /></p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb623-1"><a href="support-vector-machines.html#cb623-1"></a><span class="kw">plot</span>(fits[[<span class="dv">3</span>]], data)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-13-4.png" width="672" /></p>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb624-1"><a href="support-vector-machines.html#cb624-1"></a><span class="kw">sapply</span>(fits, err, <span class="dt">data =</span> data[train, ])</span></code></pre></div>
<pre><code>##     Radial Polynomial     Linear 
##       0.04       0.30       0.10</code></pre>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb626-1"><a href="support-vector-machines.html#cb626-1"></a><span class="kw">sapply</span>(fits, err, <span class="dt">data =</span> data[test, ])</span></code></pre></div>
<pre><code>##     Radial Polynomial     Linear 
##       0.06       0.48       0.14</code></pre>
<p>In this case, the radial kernel performs best, followed by a linear kernel with
the 2nd degree polynomial performing worst. The ordering of these models is the
same for the training and test data sets.</p>
</div>
<div id="question-5-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.2.2</span> Question 5<a href="support-vector-machines.html#question-5-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>We have seen that we can fit an SVM with a non-linear kernel in order to
perform classification using a non-linear decision boundary. We will now see
that we can also obtain a non-linear decision boundary by performing logistic
regression using non-linear transformations of the features.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Generate a data set with <span class="math inline">\(n = 500\)</span> and <span class="math inline">\(p = 2\)</span>, such that the observations
belong to two classes with a quadratic decision boundary between them. For
instance, you can do this as follows:</p>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb628-1"><a href="support-vector-machines.html#cb628-1"></a><span class="op">&gt;</span><span class="st"> </span>x1 &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">500</span>) <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb628-2"><a href="support-vector-machines.html#cb628-2"></a><span class="op">&gt;</span><span class="st"> </span>x2 &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">500</span>) <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb628-3"><a href="support-vector-machines.html#cb628-3"></a><span class="op">&gt;</span><span class="st"> </span>y &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">*</span><span class="st"> </span>(x1<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span>x2<span class="op">^</span><span class="dv">2</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)</span></code></pre></div></li>
</ol>
</blockquote>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="support-vector-machines.html#cb629-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb629-2"><a href="support-vector-machines.html#cb629-2"></a>train &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb629-3"><a href="support-vector-machines.html#cb629-3"></a>  <span class="dt">x1 =</span> <span class="kw">runif</span>(<span class="dv">500</span>) <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span>,</span>
<span id="cb629-4"><a href="support-vector-machines.html#cb629-4"></a>  <span class="dt">x2 =</span> <span class="kw">runif</span>(<span class="dv">500</span>) <span class="op">-</span><span class="st"> </span><span class="fl">0.5</span></span>
<span id="cb629-5"><a href="support-vector-machines.html#cb629-5"></a>)</span>
<span id="cb629-6"><a href="support-vector-machines.html#cb629-6"></a>train<span class="op">$</span>y &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.numeric</span>((train<span class="op">$</span>x1<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span>train<span class="op">$</span>x2<span class="op">^</span><span class="dv">2</span> <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>)))</span></code></pre></div>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Plot the observations, colored according to their class labels. Your plot
should display <span class="math inline">\(X_1\)</span> on the <span class="math inline">\(x\)</span>-axis, and <span class="math inline">\(X_2\)</span> on the <span class="math inline">\(y\)</span>-axis.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb630-1"><a href="support-vector-machines.html#cb630-1"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(train, <span class="kw">aes</span>(<span class="dt">x =</span> x1, <span class="dt">y =</span> x2, <span class="dt">color =</span> y)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb630-2"><a href="support-vector-machines.html#cb630-2"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>)</span>
<span id="cb630-3"><a href="support-vector-machines.html#cb630-3"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Fit a logistic regression model to the data, using <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> as
predictors.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb631"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb631-1"><a href="support-vector-machines.html#cb631-1"></a>fit1 &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> train, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>Apply this model to the <em>training data</em> in order to obtain a predicted class
label for each training observation. Plot the observations, colored
according to the <em>predicted</em> class labels. The decision boundary should be
linear.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb632"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb632-1"><a href="support-vector-machines.html#cb632-1"></a>plot_model &lt;-<span class="st"> </span><span class="cf">function</span>(fit) {</span>
<span id="cb632-2"><a href="support-vector-machines.html#cb632-2"></a>  <span class="cf">if</span> (<span class="kw">inherits</span>(fit, <span class="st">&quot;svm&quot;</span>)) {</span>
<span id="cb632-3"><a href="support-vector-machines.html#cb632-3"></a>    train<span class="op">$</span>p &lt;-<span class="st"> </span><span class="kw">predict</span>(fit)</span>
<span id="cb632-4"><a href="support-vector-machines.html#cb632-4"></a>  } <span class="cf">else</span> {</span>
<span id="cb632-5"><a href="support-vector-machines.html#cb632-5"></a>    train<span class="op">$</span>p &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">as.numeric</span>(<span class="kw">predict</span>(fit) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>))</span>
<span id="cb632-6"><a href="support-vector-machines.html#cb632-6"></a>  }</span>
<span id="cb632-7"><a href="support-vector-machines.html#cb632-7"></a>  <span class="kw">ggplot</span>(train, <span class="kw">aes</span>(<span class="dt">x =</span> x1, <span class="dt">y =</span> x2, <span class="dt">color =</span> p)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb632-8"><a href="support-vector-machines.html#cb632-8"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>)</span>
<span id="cb632-9"><a href="support-vector-machines.html#cb632-9"></a>}</span>
<span id="cb632-10"><a href="support-vector-machines.html#cb632-10"></a></span>
<span id="cb632-11"><a href="support-vector-machines.html#cb632-11"></a><span class="kw">plot_model</span>(fit1)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<blockquote>
<ol start="5" style="list-style-type: lower-alpha">
<li>Now fit a logistic regression model to the data using non-linear functions
of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> as predictors (e.g. <span class="math inline">\(X_1^2, X_1 \times X_2, \log(X_2),\)</span>
and so forth).</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb633"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb633-1"><a href="support-vector-machines.html#cb633-1"></a>fit2 &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span><span class="kw">poly</span>(x1, <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">poly</span>(x2, <span class="dv">2</span>), <span class="dt">data =</span> train, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: glm.fit: algorithm did not converge</code></pre>
<pre><code>## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred</code></pre>
<blockquote>
<ol start="6" style="list-style-type: lower-alpha">
<li>Apply this model to the <em>training data</em> in order to obtain a predicted
class label for each training observation. Plot the observations, colored
according to the <em>predicted</em> class labels. The decision boundary should be
obviously non-linear. If it is not, then repeat (a)-(e) until you come up
with an example in which the predicted class labels are obviously
non-linear.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="support-vector-machines.html#cb636-1"></a><span class="kw">plot_model</span>(fit2)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<blockquote>
<ol start="7" style="list-style-type: lower-alpha">
<li>Fit a support vector classifier to the data with <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> as
predictors. Obtain a class prediction for each training observation. Plot
the observations, colored according to the <em>predicted class labels</em>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb637"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb637-1"><a href="support-vector-machines.html#cb637-1"></a>fit3 &lt;-<span class="st"> </span><span class="kw">svm</span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">data =</span> train, <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>)</span>
<span id="cb637-2"><a href="support-vector-machines.html#cb637-2"></a><span class="kw">plot_model</span>(fit3)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<blockquote>
<ol start="8" style="list-style-type: lower-alpha">
<li>Fit a SVM using a non-linear kernel to the data. Obtain a class prediction
for each training observation. Plot the observations, colored according to
the <em>predicted class labels</em>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="support-vector-machines.html#cb638-1"></a>fit4 &lt;-<span class="st"> </span><span class="kw">svm</span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, <span class="dt">data =</span> train, <span class="dt">kernel =</span> <span class="st">&quot;polynomial&quot;</span>, <span class="dt">degree =</span> <span class="dv">2</span>)</span>
<span id="cb638-2"><a href="support-vector-machines.html#cb638-2"></a><span class="kw">plot_model</span>(fit4)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<blockquote>
<ol style="list-style-type: lower-roman">
<li>Comment on your results.</li>
</ol>
</blockquote>
<p>When simulating data with a quadratic decision boundary, a logistic model with
quadratic transformations of the variables and an svm model with a quadratic
kernel both produce much better (and similar fits) than standard linear methods.</p>
</div>
<div id="question-6-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.2.3</span> Question 6<a href="support-vector-machines.html#question-6-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>At the end of Section 9.6.1, it is claimed that in the case of data that is
just barely linearly separable, a support vector classifier with a small
value of <code>cost</code> that misclassifies a couple of training observations may
perform better on test data than one with a huge value of <code>cost</code> that does not
misclassify any training observations. You will now investigate this claim.</p>
<ol style="list-style-type: lower-alpha">
<li>Generate two-class data with <span class="math inline">\(p = 2\)</span> in such a way that the classes are
just barely linearly separable.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="support-vector-machines.html#cb639-1"></a><span class="kw">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb639-2"><a href="support-vector-machines.html#cb639-2"></a></span>
<span id="cb639-3"><a href="support-vector-machines.html#cb639-3"></a><span class="co"># Simulate data that is separable by a line at y = 2.5</span></span>
<span id="cb639-4"><a href="support-vector-machines.html#cb639-4"></a>data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb639-5"><a href="support-vector-machines.html#cb639-5"></a>  <span class="dt">x =</span> <span class="kw">rnorm</span>(<span class="dv">200</span>),</span>
<span id="cb639-6"><a href="support-vector-machines.html#cb639-6"></a>  <span class="dt">class =</span> <span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="dv">200</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb639-7"><a href="support-vector-machines.html#cb639-7"></a>)</span>
<span id="cb639-8"><a href="support-vector-machines.html#cb639-8"></a>data<span class="op">$</span>y &lt;-<span class="st"> </span>(data<span class="op">$</span>class <span class="op">==</span><span class="st"> &quot;red&quot;</span>) <span class="op">*</span><span class="st"> </span><span class="dv">5</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb639-9"><a href="support-vector-machines.html#cb639-9"></a></span>
<span id="cb639-10"><a href="support-vector-machines.html#cb639-10"></a><span class="co"># Add barley separable points (these are simulated &quot;noise&quot; values)</span></span>
<span id="cb639-11"><a href="support-vector-machines.html#cb639-11"></a>newdata &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(<span class="dv">30</span>))</span>
<span id="cb639-12"><a href="support-vector-machines.html#cb639-12"></a>newdata<span class="op">$</span>y &lt;-<span class="st"> </span><span class="fl">1.5</span><span class="op">*</span>newdata<span class="op">$</span>x <span class="op">+</span><span class="st"> </span><span class="dv">3</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">30</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb639-13"><a href="support-vector-machines.html#cb639-13"></a>newdata<span class="op">$</span>class =<span class="st"> </span><span class="kw">ifelse</span>((<span class="fl">1.5</span><span class="op">*</span>newdata<span class="op">$</span>x <span class="op">+</span><span class="st"> </span><span class="dv">3</span>) <span class="op">-</span><span class="st"> </span>newdata<span class="op">$</span>y <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>)</span>
<span id="cb639-14"><a href="support-vector-machines.html#cb639-14"></a></span>
<span id="cb639-15"><a href="support-vector-machines.html#cb639-15"></a>data &lt;-<span class="st"> </span><span class="kw">rbind</span>(data, newdata)</span>
<span id="cb639-16"><a href="support-vector-machines.html#cb639-16"></a></span>
<span id="cb639-17"><a href="support-vector-machines.html#cb639-17"></a><span class="co"># remove any that cause misclassification leaving data that is barley linearly</span></span>
<span id="cb639-18"><a href="support-vector-machines.html#cb639-18"></a><span class="co"># separable, but along an axis that is not y = 2.5 (which would be correct</span></span>
<span id="cb639-19"><a href="support-vector-machines.html#cb639-19"></a><span class="co"># for the &quot;true&quot; data.</span></span>
<span id="cb639-20"><a href="support-vector-machines.html#cb639-20"></a>data &lt;-<span class="st"> </span>data[<span class="op">!</span>(data<span class="op">$</span>class <span class="op">==</span><span class="st"> &quot;red&quot;</span>) <span class="op">==</span><span class="st"> </span>((<span class="fl">1.5</span><span class="op">*</span>data<span class="op">$</span>x <span class="op">+</span><span class="st"> </span><span class="dv">3</span> <span class="op">-</span><span class="st"> </span>data<span class="op">$</span>y) <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>), ]</span>
<span id="cb639-21"><a href="support-vector-machines.html#cb639-21"></a>data &lt;-<span class="st"> </span>data[<span class="kw">sample</span>(<span class="kw">seq_len</span>(<span class="kw">nrow</span>(data)), <span class="dv">200</span>), ]</span>
<span id="cb639-22"><a href="support-vector-machines.html#cb639-22"></a></span>
<span id="cb639-23"><a href="support-vector-machines.html#cb639-23"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(data, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">color =</span> class)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb639-24"><a href="support-vector-machines.html#cb639-24"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">scale_colour_identity</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb639-25"><a href="support-vector-machines.html#cb639-25"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">3</span>, <span class="dt">slope =</span> <span class="fl">1.5</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</span>
<span id="cb639-26"><a href="support-vector-machines.html#cb639-26"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Compute the cross-validation error rates for support vector classifiers
with a range of <code>cost</code> values. How many training errors are misclassified
for each value of <code>cost</code> considered, and how does this relate to the
cross-validation errors obtained?</li>
</ol>
</blockquote>
<p>How many training errors are misclassified for each value of cost?</p>
<div class="sourceCode" id="cb640"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb640-1"><a href="support-vector-machines.html#cb640-1"></a>costs &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb640-2"><a href="support-vector-machines.html#cb640-2"></a></span>
<span id="cb640-3"><a href="support-vector-machines.html#cb640-3"></a><span class="kw">sapply</span>(costs, <span class="cf">function</span>(cost) {</span>
<span id="cb640-4"><a href="support-vector-machines.html#cb640-4"></a>    fit &lt;-<span class="st"> </span><span class="kw">svm</span>(<span class="kw">as.factor</span>(class) <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data, <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>, <span class="dt">cost =</span> cost)</span>
<span id="cb640-5"><a href="support-vector-machines.html#cb640-5"></a>    pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, data)</span>
<span id="cb640-6"><a href="support-vector-machines.html#cb640-6"></a>    <span class="kw">sum</span>(pred <span class="op">!=</span><span class="st"> </span>data<span class="op">$</span>class)</span>
<span id="cb640-7"><a href="support-vector-machines.html#cb640-7"></a>})</span></code></pre></div>
<pre><code>## [1] 98  8  9  4  1  1  0  0  0</code></pre>
<p>Cross-validation errors</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="support-vector-machines.html#cb642-1"></a>out &lt;-<span class="st"> </span><span class="kw">tune</span>(svm, <span class="kw">as.factor</span>(class) <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data, <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>, <span class="dt">ranges =</span> <span class="kw">list</span>(<span class="dt">cost =</span> costs))</span>
<span id="cb642-2"><a href="support-vector-machines.html#cb642-2"></a><span class="kw">summary</span>(out)</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost
##    10
## 
## - best performance: 0.005 
## 
## - Detailed performance results:
##    cost error dispersion
## 1 1e-03 0.540 0.09067647
## 2 1e-02 0.045 0.02838231
## 3 1e-01 0.045 0.03689324
## 4 1e+00 0.020 0.02581989
## 5 1e+01 0.005 0.01581139
## 6 1e+02 0.005 0.01581139
## 7 1e+03 0.005 0.01581139
## 8 1e+04 0.010 0.02108185
## 9 1e+05 0.010 0.02108185</code></pre>
<div class="sourceCode" id="cb644"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb644-1"><a href="support-vector-machines.html#cb644-1"></a><span class="kw">data.frame</span>(</span>
<span id="cb644-2"><a href="support-vector-machines.html#cb644-2"></a>  <span class="dt">cost =</span> out<span class="op">$</span>performances<span class="op">$</span>cost, </span>
<span id="cb644-3"><a href="support-vector-machines.html#cb644-3"></a>  <span class="dt">misclass =</span> out<span class="op">$</span>performances<span class="op">$</span>error <span class="op">*</span><span class="st"> </span><span class="kw">nrow</span>(data)</span>
<span id="cb644-4"><a href="support-vector-machines.html#cb644-4"></a>)</span></code></pre></div>
<pre><code>##    cost misclass
## 1 1e-03      108
## 2 1e-02        9
## 3 1e-01        9
## 4 1e+00        4
## 5 1e+01        1
## 6 1e+02        1
## 7 1e+03        1
## 8 1e+04        2
## 9 1e+05        2</code></pre>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Generate an appropriate test data set, and compute the test errors
corresponding to each of the values of <code>cost</code> considered. Which value of
<code>cost</code> leads to the fewest test errors, and how does this compare to the
values of <code>cost</code> that yield the fewest training errors and the fewest
cross-validation errors?</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb646-1"><a href="support-vector-machines.html#cb646-1"></a><span class="kw">set.seed</span>(<span class="dv">2</span>)</span>
<span id="cb646-2"><a href="support-vector-machines.html#cb646-2"></a>test &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb646-3"><a href="support-vector-machines.html#cb646-3"></a>  <span class="dt">x =</span> <span class="kw">rnorm</span>(<span class="dv">200</span>),</span>
<span id="cb646-4"><a href="support-vector-machines.html#cb646-4"></a>  <span class="dt">class =</span> <span class="kw">sample</span>(<span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="dv">200</span>, <span class="dt">replace =</span> <span class="ot">TRUE</span>)</span>
<span id="cb646-5"><a href="support-vector-machines.html#cb646-5"></a>)</span>
<span id="cb646-6"><a href="support-vector-machines.html#cb646-6"></a>test<span class="op">$</span>y &lt;-<span class="st"> </span>(test<span class="op">$</span>class <span class="op">==</span><span class="st"> &quot;red&quot;</span>) <span class="op">*</span><span class="st"> </span><span class="dv">5</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">200</span>)</span>
<span id="cb646-7"><a href="support-vector-machines.html#cb646-7"></a>p <span class="op">+</span><span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data =</span> test, <span class="dt">pch =</span> <span class="dv">21</span>)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<div class="sourceCode" id="cb647"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb647-1"><a href="support-vector-machines.html#cb647-1"></a>(errs &lt;-<span class="st"> </span><span class="kw">sapply</span>(costs, <span class="cf">function</span>(cost) {</span>
<span id="cb647-2"><a href="support-vector-machines.html#cb647-2"></a>    fit &lt;-<span class="st"> </span><span class="kw">svm</span>(<span class="kw">as.factor</span>(class) <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data, <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>, <span class="dt">cost =</span> cost)</span>
<span id="cb647-3"><a href="support-vector-machines.html#cb647-3"></a>    pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, test)</span>
<span id="cb647-4"><a href="support-vector-machines.html#cb647-4"></a>    <span class="kw">sum</span>(pred <span class="op">!=</span><span class="st"> </span>test<span class="op">$</span>class)</span>
<span id="cb647-5"><a href="support-vector-machines.html#cb647-5"></a>}))</span></code></pre></div>
<pre><code>## [1] 95  2  3  9 16 16 19 19 19</code></pre>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb649-1"><a href="support-vector-machines.html#cb649-1"></a>(cost &lt;-<span class="st"> </span>costs[<span class="kw">which.min</span>(errs)])</span></code></pre></div>
<pre><code>## [1] 0.01</code></pre>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="support-vector-machines.html#cb651-1"></a>(fit &lt;-<span class="st"> </span><span class="kw">svm</span>(<span class="kw">as.factor</span>(class) <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> data, <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>, <span class="dt">cost =</span> cost))</span></code></pre></div>
<pre><code>## 
## Call:
## svm(formula = as.factor(class) ~ ., data = data, kernel = &quot;linear&quot;, 
##     cost = cost)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  0.01 
## 
## Number of Support Vectors:  135</code></pre>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="support-vector-machines.html#cb653-1"></a>test<span class="op">$</span>prediction &lt;-<span class="st"> </span><span class="kw">predict</span>(fit, test)</span>
<span id="cb653-2"><a href="support-vector-machines.html#cb653-2"></a>p &lt;-<span class="st"> </span><span class="kw">ggplot</span>(test, <span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y, <span class="dt">color =</span> class, <span class="dt">shape =</span> prediction <span class="op">==</span><span class="st"> </span>class)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb653-3"><a href="support-vector-machines.html#cb653-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">size =</span> <span class="dv">2</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb653-4"><a href="support-vector-machines.html#cb653-4"></a><span class="st">  </span><span class="kw">scale_colour_identity</span>() </span>
<span id="cb653-5"><a href="support-vector-machines.html#cb653-5"></a>p</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-25-2.png" width="672" /></p>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>Discuss your results.</li>
</ol>
</blockquote>
<p>A large cost leads to overfitting as the model finds the perfect linear
separation between red and blue in the training data. A lower cost then
leads to improved prediction in the test data.</p>
</div>
<div id="question-7-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.2.4</span> Question 7<a href="support-vector-machines.html#question-7-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>In this problem, you will use support vector approaches in order to predict
whether a given car gets high or low gas mileage based on the <code>Auto</code> data set.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a binary variable that takes on a 1 for cars with gas mileage above
the median, and a 0 for cars with gas mileage below the median.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb654"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb654-1"><a href="support-vector-machines.html#cb654-1"></a><span class="kw">library</span>(ISLR2)</span>
<span id="cb654-2"><a href="support-vector-machines.html#cb654-2"></a>data &lt;-<span class="st"> </span>Auto</span>
<span id="cb654-3"><a href="support-vector-machines.html#cb654-3"></a>data<span class="op">$</span>high_mpg &lt;-<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">as.numeric</span>(data<span class="op">$</span>mpg <span class="op">&gt;</span><span class="st"> </span><span class="kw">median</span>(data<span class="op">$</span>mpg)))</span></code></pre></div>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Fit a support vector classifier to the data with various values of <code>cost</code>,
in order to predict whether a car gets high or low gas mileage. Report the
cross-validation errors associated with different values of this parameter.
Comment on your results. Note you will need to fit the classifier without
the gas mileage variable to produce sensible results.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="support-vector-machines.html#cb655-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb655-2"><a href="support-vector-machines.html#cb655-2"></a>costs &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">4</span>, <span class="dv">3</span>, <span class="dt">by =</span> <span class="fl">0.5</span>)</span>
<span id="cb655-3"><a href="support-vector-machines.html#cb655-3"></a>results &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb655-4"><a href="support-vector-machines.html#cb655-4"></a>f &lt;-<span class="st"> </span>high_mpg <span class="op">~</span><span class="st"> </span>displacement <span class="op">+</span><span class="st"> </span>horsepower <span class="op">+</span><span class="st"> </span>weight</span>
<span id="cb655-5"><a href="support-vector-machines.html#cb655-5"></a>results<span class="op">$</span>linear &lt;-<span class="st"> </span><span class="kw">tune</span>(svm, f, <span class="dt">data =</span> data, <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>, </span>
<span id="cb655-6"><a href="support-vector-machines.html#cb655-6"></a>  <span class="dt">ranges =</span> <span class="kw">list</span>(<span class="dt">cost =</span> costs))</span>
<span id="cb655-7"><a href="support-vector-machines.html#cb655-7"></a><span class="kw">summary</span>(results<span class="op">$</span>linear)</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##        cost
##  0.03162278
## 
## - best performance: 0.1019231 
## 
## - Detailed performance results:
##            cost     error dispersion
## 1  1.000000e-04 0.5967949 0.05312225
## 2  3.162278e-04 0.5967949 0.05312225
## 3  1.000000e-03 0.2199359 0.08718077
## 4  3.162278e-03 0.1353846 0.06058195
## 5  1.000000e-02 0.1121795 0.04011293
## 6  3.162278e-02 0.1019231 0.05087176
## 7  1.000000e-01 0.1096154 0.05246238
## 8  3.162278e-01 0.1044872 0.05154934
## 9  1.000000e+00 0.1044872 0.05154934
## 10 3.162278e+00 0.1044872 0.05154934
## 11 1.000000e+01 0.1019231 0.05501131
## 12 3.162278e+01 0.1019231 0.05501131
## 13 1.000000e+02 0.1019231 0.05501131
## 14 3.162278e+02 0.1019231 0.05501131
## 15 1.000000e+03 0.1019231 0.05501131</code></pre>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Now repeat (b), this time using SVMs with radial and polynomial basis
kernels, with different values of <code>gamma</code> and <code>degree</code> and <code>cost</code>. Comment
on your results.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="support-vector-machines.html#cb657-1"></a>results<span class="op">$</span>polynomial &lt;-<span class="st"> </span><span class="kw">tune</span>(svm, f, <span class="dt">data =</span> data, <span class="dt">kernel =</span> <span class="st">&quot;polynomial&quot;</span>, </span>
<span id="cb657-2"><a href="support-vector-machines.html#cb657-2"></a>  <span class="dt">ranges =</span> <span class="kw">list</span>(<span class="dt">cost =</span> costs, <span class="dt">degree =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>))</span>
<span id="cb657-3"><a href="support-vector-machines.html#cb657-3"></a><span class="kw">summary</span>(results<span class="op">$</span>polynomial)</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost degree
##   0.1      1
## 
## - best performance: 0.101859 
## 
## - Detailed performance results:
##            cost degree     error dispersion
## 1  1.000000e-04      1 0.5842949 0.04703306
## 2  3.162278e-04      1 0.5842949 0.04703306
## 3  1.000000e-03      1 0.5842949 0.04703306
## 4  3.162278e-03      1 0.2167949 0.07891173
## 5  1.000000e-02      1 0.1275641 0.04806885
## 6  3.162278e-02      1 0.1147436 0.05661708
## 7  1.000000e-01      1 0.1018590 0.05732429
## 8  3.162278e-01      1 0.1069231 0.05949679
## 9  1.000000e+00      1 0.1069231 0.06307278
## 10 3.162278e+00      1 0.1069231 0.06307278
## 11 1.000000e+01      1 0.1043590 0.06603760
## 12 3.162278e+01      1 0.1043590 0.06603760
## 13 1.000000e+02      1 0.1043590 0.06603760
## 14 3.162278e+02      1 0.1043590 0.06603760
## 15 1.000000e+03      1 0.1043590 0.06603760
## 16 1.000000e-04      2 0.5842949 0.04703306
## 17 3.162278e-04      2 0.5842949 0.04703306
## 18 1.000000e-03      2 0.5842949 0.04703306
## 19 3.162278e-03      2 0.5255128 0.08090636
## 20 1.000000e-02      2 0.3980769 0.08172400
## 21 3.162278e-02      2 0.3674359 0.07974741
## 22 1.000000e-01      2 0.3597436 0.08336609
## 23 3.162278e-01      2 0.3597436 0.09010398
## 24 1.000000e+00      2 0.3444872 0.08767258
## 25 3.162278e+00      2 0.3545513 0.10865903
## 26 1.000000e+01      2 0.3239103 0.09593710
## 27 3.162278e+01      2 0.3035256 0.08184137
## 28 1.000000e+02      2 0.3061538 0.08953945
## 29 3.162278e+02      2 0.3060897 0.08919821
## 30 1.000000e+03      2 0.3035897 0.09305216
## 31 1.000000e-04      3 0.5842949 0.04703306
## 32 3.162278e-04      3 0.4955128 0.10081350
## 33 1.000000e-03      3 0.3750641 0.08043982
## 34 3.162278e-03      3 0.3036538 0.09096445
## 35 1.000000e-02      3 0.2601282 0.07774595
## 36 3.162278e-02      3 0.2499359 0.08407106
## 37 1.000000e-01      3 0.2017949 0.07547413
## 38 3.162278e-01      3 0.1937179 0.08427411
## 39 1.000000e+00      3 0.1478205 0.04579654
## 40 3.162278e+00      3 0.1451923 0.05169638
## 41 1.000000e+01      3 0.1451282 0.04698931
## 42 3.162278e+01      3 0.1500000 0.07549058
## 43 1.000000e+02      3 0.1373718 0.05772558
## 44 3.162278e+02      3 0.1271795 0.06484766
## 45 1.000000e+03      3 0.1322436 0.06764841</code></pre>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="support-vector-machines.html#cb659-1"></a>results<span class="op">$</span>radial &lt;-<span class="st"> </span><span class="kw">tune</span>(svm, f, <span class="dt">data =</span> data, <span class="dt">kernel =</span> <span class="st">&quot;radial&quot;</span>, </span>
<span id="cb659-2"><a href="support-vector-machines.html#cb659-2"></a>  <span class="dt">ranges =</span> <span class="kw">list</span>(<span class="dt">cost =</span> costs, <span class="dt">gamma =</span> <span class="dv">10</span><span class="op">^</span>(<span class="op">-</span><span class="dv">2</span><span class="op">:</span><span class="dv">1</span>)))</span>
<span id="cb659-3"><a href="support-vector-machines.html#cb659-3"></a><span class="kw">summary</span>(results<span class="op">$</span>radial)</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost gamma
##  1000   0.1
## 
## - best performance: 0.08179487 
## 
## - Detailed performance results:
##            cost gamma      error dispersion
## 1  1.000000e-04  0.01 0.58410256 0.05435320
## 2  3.162278e-04  0.01 0.58410256 0.05435320
## 3  1.000000e-03  0.01 0.58410256 0.05435320
## 4  3.162278e-03  0.01 0.58410256 0.05435320
## 5  1.000000e-02  0.01 0.58410256 0.05435320
## 6  3.162278e-02  0.01 0.26557692 0.10963269
## 7  1.000000e-01  0.01 0.15038462 0.05783237
## 8  3.162278e-01  0.01 0.11224359 0.04337812
## 9  1.000000e+00  0.01 0.10730769 0.04512161
## 10 3.162278e+00  0.01 0.10730769 0.04512161
## 11 1.000000e+01  0.01 0.10737179 0.05526490
## 12 3.162278e+01  0.01 0.10480769 0.05610124
## 13 1.000000e+02  0.01 0.10480769 0.05610124
## 14 3.162278e+02  0.01 0.10737179 0.05526490
## 15 1.000000e+03  0.01 0.10993590 0.05690926
## 16 1.000000e-04  0.10 0.58410256 0.05435320
## 17 3.162278e-04  0.10 0.58410256 0.05435320
## 18 1.000000e-03  0.10 0.58410256 0.05435320
## 19 3.162278e-03  0.10 0.58410256 0.05435320
## 20 1.000000e-02  0.10 0.15301282 0.06026554
## 21 3.162278e-02  0.10 0.11480769 0.04514816
## 22 1.000000e-01  0.10 0.10730769 0.04512161
## 23 3.162278e-01  0.10 0.10730769 0.04512161
## 24 1.000000e+00  0.10 0.10737179 0.05526490
## 25 3.162278e+00  0.10 0.10737179 0.05526490
## 26 1.000000e+01  0.10 0.10737179 0.05526490
## 27 3.162278e+01  0.10 0.10737179 0.05526490
## 28 1.000000e+02  0.10 0.09967949 0.04761387
## 29 3.162278e+02  0.10 0.08429487 0.03207585
## 30 1.000000e+03  0.10 0.08179487 0.03600437
## 31 1.000000e-04  1.00 0.58410256 0.05435320
## 32 3.162278e-04  1.00 0.58410256 0.05435320
## 33 1.000000e-03  1.00 0.58410256 0.05435320
## 34 3.162278e-03  1.00 0.58410256 0.05435320
## 35 1.000000e-02  1.00 0.12506410 0.05342773
## 36 3.162278e-02  1.00 0.10730769 0.06255920
## 37 1.000000e-01  1.00 0.10993590 0.05561080
## 38 3.162278e-01  1.00 0.10737179 0.05526490
## 39 1.000000e+00  1.00 0.09711538 0.05107441
## 40 3.162278e+00  1.00 0.08429487 0.03634646
## 41 1.000000e+01  1.00 0.08692308 0.03877861
## 42 3.162278e+01  1.00 0.08948718 0.03503648
## 43 1.000000e+02  1.00 0.09198718 0.03272127
## 44 3.162278e+02  1.00 0.10217949 0.04214031
## 45 1.000000e+03  1.00 0.09692308 0.04645046
## 46 1.000000e-04 10.00 0.58410256 0.05435320
## 47 3.162278e-04 10.00 0.58410256 0.05435320
## 48 1.000000e-03 10.00 0.58410256 0.05435320
## 49 3.162278e-03 10.00 0.58410256 0.05435320
## 50 1.000000e-02 10.00 0.58410256 0.05435320
## 51 3.162278e-02 10.00 0.22205128 0.12710181
## 52 1.000000e-01 10.00 0.11237179 0.03888895
## 53 3.162278e-01 10.00 0.10217949 0.04375722
## 54 1.000000e+00 10.00 0.09717949 0.03809440
## 55 3.162278e+00 10.00 0.09717949 0.03809440
## 56 1.000000e+01 10.00 0.09711538 0.04161705
## 57 3.162278e+01 10.00 0.11487179 0.04240664
## 58 1.000000e+02 10.00 0.13019231 0.03541140
## 59 3.162278e+02 10.00 0.13532051 0.03865626
## 60 1.000000e+03 10.00 0.14044872 0.04251917</code></pre>
<div class="sourceCode" id="cb661"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb661-1"><a href="support-vector-machines.html#cb661-1"></a><span class="kw">sapply</span>(results, <span class="cf">function</span>(x) x<span class="op">$</span>best.performance)</span></code></pre></div>
<pre><code>##     linear polynomial     radial 
## 0.10192308 0.10185897 0.08179487</code></pre>
<div class="sourceCode" id="cb663"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb663-1"><a href="support-vector-machines.html#cb663-1"></a><span class="kw">sapply</span>(results, <span class="cf">function</span>(x) x<span class="op">$</span>best.parameters)</span></code></pre></div>
<pre><code>## $linear
##         cost
## 6 0.03162278
## 
## $polynomial
##   cost degree
## 7  0.1      1
## 
## $radial
##    cost gamma
## 30 1000   0.1</code></pre>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li><p>Make some plots to back up your assertions in (b) and (c).</p>
<p><em>Hint: In the lab, we used the <code>plot()</code> function for <code>svm</code> objects only in
cases with <span class="math inline">\(p = 2\)</span>. When <span class="math inline">\(p &gt; 2\)</span>, you can use the <code>plot()</code> function to
create plots displaying pairs of variables at a time. Essentially, instead
of typing</em></p>
<div class="sourceCode" id="cb665"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb665-1"><a href="support-vector-machines.html#cb665-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(svmfit, dat)</span></code></pre></div>
<p><em>where <code>svmfit</code> contains your fitted model and dat is a data frame
containing your data, you can type</em></p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="support-vector-machines.html#cb666-1"></a><span class="op">&gt;</span><span class="st"> </span><span class="kw">plot</span>(svmfit, dat, x1 ∼ x4)</span></code></pre></div>
<p><em>in order to plot just the first and fourth variables. However, you must
replace <code>x1</code> and <code>x4</code> with the correct variable names. To find out more,
type <code>?plot.svm</code>.</em></p></li>
</ol>
</blockquote>
<div class="sourceCode" id="cb667"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb667-1"><a href="support-vector-machines.html#cb667-1"></a><span class="kw">table</span>(<span class="kw">predict</span>(results<span class="op">$</span>radial<span class="op">$</span>best.model, data), data<span class="op">$</span>high_mpg)</span></code></pre></div>
<pre><code>##    
##       0   1
##   0 176   5
##   1  20 191</code></pre>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="support-vector-machines.html#cb669-1"></a><span class="kw">plot</span>(results<span class="op">$</span>radial<span class="op">$</span>best.model, data, horsepower<span class="op">~</span>displacement)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="support-vector-machines.html#cb670-1"></a><span class="kw">plot</span>(results<span class="op">$</span>radial<span class="op">$</span>best.model, data, horsepower<span class="op">~</span>weight)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-29-2.png" width="672" /></p>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="support-vector-machines.html#cb671-1"></a><span class="kw">plot</span>(results<span class="op">$</span>radial<span class="op">$</span>best.model, data, displacement<span class="op">~</span>weight)</span></code></pre></div>
<p><img src="09-support-vector-mechines_files/figure-html/unnamed-chunk-29-3.png" width="672" /></p>
</div>
<div id="question-8-7" class="section level3 hasAnchor">
<h3><span class="header-section-number">9.2.5</span> Question 8<a href="support-vector-machines.html#question-8-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>This problem involves the <code>OJ</code> data set which is part of the <code>ISLR2</code> package.</p>
<ol style="list-style-type: lower-alpha">
<li>Create a training set containing a random sample of 800 observations, and a
test set containing the remaining observations.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb672-1"><a href="support-vector-machines.html#cb672-1"></a><span class="kw">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb672-2"><a href="support-vector-machines.html#cb672-2"></a>train &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">seq_len</span>(<span class="kw">nrow</span>(OJ)), <span class="dv">800</span>)</span>
<span id="cb672-3"><a href="support-vector-machines.html#cb672-3"></a>test &lt;-<span class="st"> </span><span class="kw">setdiff</span>(<span class="kw">seq_len</span>(<span class="kw">nrow</span>(OJ)), train)</span></code></pre></div>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Fit a support vector classifier to the training data using <code>cost = 0.01</code>,
with <code>Purchase</code> as the response and the other variables as predictors. Use
the <code>summary()</code> function to produce summary statistics, and describe the
results obtained.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="support-vector-machines.html#cb673-1"></a>fit &lt;-<span class="st"> </span><span class="kw">svm</span>(Purchase <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> OJ[train, ], <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>, <span class="dt">cost =</span> <span class="fl">0.01</span>)</span>
<span id="cb673-2"><a href="support-vector-machines.html#cb673-2"></a><span class="kw">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## svm(formula = Purchase ~ ., data = OJ[train, ], kernel = &quot;linear&quot;, 
##     cost = 0.01)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  linear 
##        cost:  0.01 
## 
## Number of Support Vectors:  432
## 
##  ( 215 217 )
## 
## 
## Number of Classes:  2 
## 
## Levels: 
##  CH MM</code></pre>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>What are the training and test error rates?</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="support-vector-machines.html#cb675-1"></a>err &lt;-<span class="st"> </span><span class="cf">function</span>(model, data) {</span>
<span id="cb675-2"><a href="support-vector-machines.html#cb675-2"></a>  t &lt;-<span class="st"> </span><span class="kw">table</span>(<span class="kw">predict</span>(model, data), data[[<span class="st">&quot;Purchase&quot;</span>]])</span>
<span id="cb675-3"><a href="support-vector-machines.html#cb675-3"></a>  <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">diag</span>(t)) <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(t)</span>
<span id="cb675-4"><a href="support-vector-machines.html#cb675-4"></a>}</span>
<span id="cb675-5"><a href="support-vector-machines.html#cb675-5"></a>errs &lt;-<span class="st"> </span><span class="cf">function</span>(model) {</span>
<span id="cb675-6"><a href="support-vector-machines.html#cb675-6"></a>  <span class="kw">c</span>(<span class="dt">train =</span> <span class="kw">err</span>(model, OJ[train, ]), <span class="dt">test =</span> <span class="kw">err</span>(model, OJ[test, ]))</span>
<span id="cb675-7"><a href="support-vector-machines.html#cb675-7"></a>}</span>
<span id="cb675-8"><a href="support-vector-machines.html#cb675-8"></a><span class="kw">errs</span>(fit)</span></code></pre></div>
<pre><code>##    train     test 
## 0.171250 0.162963</code></pre>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>Use the <code>tune()</code> function to select an optimal cost. Consider values in the
range 0.01 to 10.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="support-vector-machines.html#cb677-1"></a>tuned &lt;-<span class="st"> </span><span class="kw">tune</span>(svm, Purchase <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> OJ[train, ], <span class="dt">kernel =</span> <span class="st">&quot;linear&quot;</span>, </span>
<span id="cb677-2"><a href="support-vector-machines.html#cb677-2"></a>  <span class="dt">ranges =</span> <span class="kw">list</span>(<span class="dt">cost =</span> <span class="dv">10</span><span class="op">^</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">10</span>)))</span>
<span id="cb677-3"><a href="support-vector-machines.html#cb677-3"></a>tuned<span class="op">$</span>best.parameters</span></code></pre></div>
<pre><code>##   cost
## 7    1</code></pre>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="support-vector-machines.html#cb679-1"></a><span class="kw">summary</span>(tuned)</span></code></pre></div>
<pre><code>## 
## Parameter tuning of &#39;svm&#39;:
## 
## - sampling method: 10-fold cross validation 
## 
## - best parameters:
##  cost
##     1
## 
## - best performance: 0.1775 
## 
## - Detailed performance results:
##           cost   error dispersion
## 1   0.01000000 0.18250 0.04133199
## 2   0.02154435 0.18000 0.04005205
## 3   0.04641589 0.18000 0.05041494
## 4   0.10000000 0.18000 0.04901814
## 5   0.21544347 0.18250 0.04377975
## 6   0.46415888 0.18250 0.04090979
## 7   1.00000000 0.17750 0.04031129
## 8   2.15443469 0.18000 0.03961621
## 9   4.64158883 0.17875 0.03821086
## 10 10.00000000 0.18375 0.03438447</code></pre>
<blockquote>
<ol start="5" style="list-style-type: lower-alpha">
<li>Compute the training and test error rates using this new value for <code>cost</code>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb681"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb681-1"><a href="support-vector-machines.html#cb681-1"></a><span class="kw">errs</span>(tuned<span class="op">$</span>best.model)</span></code></pre></div>
<pre><code>##    train     test 
## 0.167500 0.162963</code></pre>
<blockquote>
<ol start="6" style="list-style-type: lower-alpha">
<li>Repeat parts (b) through (e) using a support vector machine with a radial
kernel. Use the default value for <code>gamma</code>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb683-1"><a href="support-vector-machines.html#cb683-1"></a>tuned2 &lt;-<span class="st"> </span><span class="kw">tune</span>(svm, Purchase <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> OJ[train, ], <span class="dt">kernel =</span> <span class="st">&quot;radial&quot;</span>, </span>
<span id="cb683-2"><a href="support-vector-machines.html#cb683-2"></a>  <span class="dt">ranges =</span> <span class="kw">list</span>(<span class="dt">cost =</span> <span class="dv">10</span><span class="op">^</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">10</span>)))</span>
<span id="cb683-3"><a href="support-vector-machines.html#cb683-3"></a>tuned2<span class="op">$</span>best.parameters</span></code></pre></div>
<pre><code>##        cost
## 6 0.4641589</code></pre>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb685-1"><a href="support-vector-machines.html#cb685-1"></a><span class="kw">errs</span>(tuned2<span class="op">$</span>best.model)</span></code></pre></div>
<pre><code>##     train      test 
## 0.1525000 0.1666667</code></pre>
<blockquote>
<ol start="7" style="list-style-type: lower-alpha">
<li>Repeat parts (b) through (e) using a support vector machine with a
polynomial kernel. Set <code>degree = 2</code>.</li>
</ol>
</blockquote>
<div class="sourceCode" id="cb687"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb687-1"><a href="support-vector-machines.html#cb687-1"></a>tuned3 &lt;-<span class="st"> </span><span class="kw">tune</span>(svm, Purchase <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> OJ[train, ], <span class="dt">kernel =</span> <span class="st">&quot;polynomial&quot;</span>, </span>
<span id="cb687-2"><a href="support-vector-machines.html#cb687-2"></a>  <span class="dt">ranges =</span> <span class="kw">list</span>(<span class="dt">cost =</span> <span class="dv">10</span><span class="op">^</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">10</span>)), <span class="dt">degree =</span> <span class="dv">2</span>)</span>
<span id="cb687-3"><a href="support-vector-machines.html#cb687-3"></a>tuned3<span class="op">$</span>best.parameters</span></code></pre></div>
<pre><code>##       cost
## 9 4.641589</code></pre>
<div class="sourceCode" id="cb689"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb689-1"><a href="support-vector-machines.html#cb689-1"></a><span class="kw">errs</span>(tuned3<span class="op">$</span>best.model)</span></code></pre></div>
<pre><code>##     train      test 
## 0.1487500 0.1703704</code></pre>
<blockquote>
<ol start="8" style="list-style-type: lower-alpha">
<li>Overall, which approach seems to give the best results on this data?</li>
</ol>
</blockquote>
<p>Overall the “radial” kernel appears to perform best in this case.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tree-based-methods.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="deep-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": {}
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/danhalligan/ISLRv2-solutions/edit/master/09-support-vector-mechines.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
